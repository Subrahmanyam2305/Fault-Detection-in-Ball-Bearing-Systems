{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Reshape,Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Input\n",
    "from keras.layers import concatenate\n",
    "from keras import Model\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D ,GlobalMaxPooling1D\n",
    "from math import sqrt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 1000, 2)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1000, 2)      0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 985, 8)       264         reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 970, 8)       1032        conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 955, 8)       1032        conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 940, 8)       1032        conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 1, 8)         0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 1, 8)         0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 1, 8)         0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 1, 8)         0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 8)            0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 8)            0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 8)            0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 8)            0           max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32)           0           flatten_9[0][0]                  \n",
      "                                                                 flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           528         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           170         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,058\n",
      "Trainable params: 4,058\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(1000,2))\n",
    "x = Reshape((1000, 2), input_shape=(1000,2))(inp)\n",
    "x = Conv1D(8, 16, activation='relu', input_shape=(1000,2))(x)\n",
    "x1=MaxPooling1D(985)(x)\n",
    "x1=Flatten()(x1)\n",
    "x = Conv1D(8, 16, activation='relu')(x)\n",
    "x2=MaxPooling1D(970)(x)\n",
    "x2 = Flatten()(x2)\n",
    "x = Conv1D(8, 16, activation='relu')(x)\n",
    "x3=MaxPooling1D(955)(x)\n",
    "x3 = Flatten()(x3)\n",
    "x = Conv1D(8, 16, activation='relu')(x)\n",
    "x4=MaxPooling1D(940)(x)\n",
    "x4 = Flatten()(x4)\n",
    "c= concatenate([x1, x2 , x3 , x4])\n",
    "x=Dropout(0.1)(c)\n",
    "x=Dense(16,activation=\"relu\")(x)\n",
    "x=Dense(10,activation=\"softmax\")(x)\n",
    "model_c3 = Model(inputs=inp, outputs=x)\n",
    "model_c3.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_c3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 168 samples, validate on 72 samples\n",
      "Epoch 1/1500\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.3035 - acc: 0.1131 - val_loss: 2.4650 - val_acc: 0.0000e+00\n",
      "Epoch 2/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 2.2930 - acc: 0.1369 - val_loss: 2.4870 - val_acc: 0.0000e+00\n",
      "Epoch 3/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 2.2857 - acc: 0.1250 - val_loss: 2.5100 - val_acc: 0.0000e+00\n",
      "Epoch 4/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 2.2825 - acc: 0.1488 - val_loss: 2.5376 - val_acc: 0.0000e+00\n",
      "Epoch 5/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 2.2750 - acc: 0.1250 - val_loss: 2.5685 - val_acc: 0.0000e+00\n",
      "Epoch 6/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 2.2688 - acc: 0.1607 - val_loss: 2.6015 - val_acc: 0.0000e+00\n",
      "Epoch 7/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 2.2602 - acc: 0.1786 - val_loss: 2.6371 - val_acc: 0.0000e+00\n",
      "Epoch 8/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 2.2537 - acc: 0.1548 - val_loss: 2.6781 - val_acc: 0.0000e+00\n",
      "Epoch 9/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 2.2447 - acc: 0.1607 - val_loss: 2.7254 - val_acc: 0.0000e+00\n",
      "Epoch 10/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 2.2393 - acc: 0.1964 - val_loss: 2.7785 - val_acc: 0.0000e+00\n",
      "Epoch 11/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 2.2371 - acc: 0.1905 - val_loss: 2.8371 - val_acc: 0.0000e+00\n",
      "Epoch 12/1500\n",
      "168/168 [==============================] - 0s 864us/step - loss: 2.2310 - acc: 0.1548 - val_loss: 2.9008 - val_acc: 0.0000e+00\n",
      "Epoch 13/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 2.2189 - acc: 0.1488 - val_loss: 2.9700 - val_acc: 0.0000e+00\n",
      "Epoch 14/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 2.2148 - acc: 0.1429 - val_loss: 3.0473 - val_acc: 0.0000e+00\n",
      "Epoch 15/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 2.2099 - acc: 0.1548 - val_loss: 3.1309 - val_acc: 0.0000e+00\n",
      "Epoch 16/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 2.1981 - acc: 0.1607 - val_loss: 3.2221 - val_acc: 0.0000e+00\n",
      "Epoch 17/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 2.1845 - acc: 0.1250 - val_loss: 3.3204 - val_acc: 0.0000e+00\n",
      "Epoch 18/1500\n",
      "168/168 [==============================] - 0s 852us/step - loss: 2.1763 - acc: 0.1726 - val_loss: 3.4306 - val_acc: 0.0000e+00\n",
      "Epoch 19/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 2.1698 - acc: 0.1667 - val_loss: 3.5513 - val_acc: 0.0000e+00\n",
      "Epoch 20/1500\n",
      "168/168 [==============================] - 0s 814us/step - loss: 2.1600 - acc: 0.1250 - val_loss: 3.6872 - val_acc: 0.0000e+00\n",
      "Epoch 21/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 2.1502 - acc: 0.1369 - val_loss: 3.8356 - val_acc: 0.0000e+00\n",
      "Epoch 22/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 2.1447 - acc: 0.1548 - val_loss: 4.0022 - val_acc: 0.0000e+00\n",
      "Epoch 23/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 2.1354 - acc: 0.1488 - val_loss: 4.1815 - val_acc: 0.0000e+00\n",
      "Epoch 24/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 2.1210 - acc: 0.1429 - val_loss: 4.3751 - val_acc: 0.0000e+00\n",
      "Epoch 25/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 2.1199 - acc: 0.1488 - val_loss: 4.5765 - val_acc: 0.0000e+00\n",
      "Epoch 26/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 2.0973 - acc: 0.1488 - val_loss: 4.7837 - val_acc: 0.0000e+00\n",
      "Epoch 27/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 2.0943 - acc: 0.1488 - val_loss: 4.9862 - val_acc: 0.0000e+00\n",
      "Epoch 28/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 2.0851 - acc: 0.1429 - val_loss: 5.1814 - val_acc: 0.0000e+00\n",
      "Epoch 29/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 2.0807 - acc: 0.1488 - val_loss: 5.3617 - val_acc: 0.0000e+00\n",
      "Epoch 30/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 2.0680 - acc: 0.1488 - val_loss: 5.5222 - val_acc: 0.0000e+00\n",
      "Epoch 31/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 2.0651 - acc: 0.1488 - val_loss: 5.6538 - val_acc: 0.0000e+00\n",
      "Epoch 32/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 2.0463 - acc: 0.1488 - val_loss: 5.7660 - val_acc: 0.0000e+00\n",
      "Epoch 33/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 2.0263 - acc: 0.1607 - val_loss: 5.8619 - val_acc: 0.0000e+00\n",
      "Epoch 34/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 2.0140 - acc: 0.1548 - val_loss: 5.9507 - val_acc: 0.0000e+00\n",
      "Epoch 35/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 2.0045 - acc: 0.1667 - val_loss: 6.0280 - val_acc: 0.0000e+00\n",
      "Epoch 36/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 2.0080 - acc: 0.1726 - val_loss: 6.1000 - val_acc: 0.0000e+00\n",
      "Epoch 37/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 2.0042 - acc: 0.1667 - val_loss: 6.1646 - val_acc: 0.0000e+00\n",
      "Epoch 38/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 1.9822 - acc: 0.2024 - val_loss: 6.2257 - val_acc: 0.0000e+00\n",
      "Epoch 39/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 1.9509 - acc: 0.1964 - val_loss: 6.2904 - val_acc: 0.0000e+00\n",
      "Epoch 40/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 1.9483 - acc: 0.1845 - val_loss: 6.3599 - val_acc: 0.0000e+00\n",
      "Epoch 41/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 1.9354 - acc: 0.1905 - val_loss: 6.4453 - val_acc: 0.0000e+00\n",
      "Epoch 42/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 1.9149 - acc: 0.2381 - val_loss: 6.5482 - val_acc: 0.0000e+00\n",
      "Epoch 43/1500\n",
      "168/168 [==============================] - 0s 868us/step - loss: 1.9138 - acc: 0.2381 - val_loss: 6.6609 - val_acc: 0.0000e+00\n",
      "Epoch 44/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 1.9098 - acc: 0.2143 - val_loss: 6.7697 - val_acc: 0.0000e+00\n",
      "Epoch 45/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 1.8759 - acc: 0.2381 - val_loss: 6.8855 - val_acc: 0.0000e+00\n",
      "Epoch 46/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 1.8532 - acc: 0.2202 - val_loss: 7.0260 - val_acc: 0.0000e+00\n",
      "Epoch 47/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 1.8616 - acc: 0.2500 - val_loss: 7.1603 - val_acc: 0.0000e+00\n",
      "Epoch 48/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 1.8484 - acc: 0.2202 - val_loss: 7.2931 - val_acc: 0.0000e+00\n",
      "Epoch 49/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 1.8334 - acc: 0.2321 - val_loss: 7.4162 - val_acc: 0.0000e+00\n",
      "Epoch 50/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 1.8328 - acc: 0.2202 - val_loss: 7.5280 - val_acc: 0.0000e+00\n",
      "Epoch 51/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 1.8159 - acc: 0.2560 - val_loss: 7.6184 - val_acc: 0.0000e+00\n",
      "Epoch 52/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 1.7942 - acc: 0.2143 - val_loss: 7.6908 - val_acc: 0.0000e+00\n",
      "Epoch 53/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 1.7763 - acc: 0.2500 - val_loss: 7.7801 - val_acc: 0.0000e+00\n",
      "Epoch 54/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 1.7609 - acc: 0.3095 - val_loss: 7.8766 - val_acc: 0.0000e+00\n",
      "Epoch 55/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 1.7510 - acc: 0.2917 - val_loss: 7.9850 - val_acc: 0.0000e+00\n",
      "Epoch 56/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 1.7488 - acc: 0.3214 - val_loss: 8.0782 - val_acc: 0.0000e+00\n",
      "Epoch 57/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 1.7010 - acc: 0.3095 - val_loss: 8.1831 - val_acc: 0.0000e+00\n",
      "Epoch 58/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 1.7033 - acc: 0.3274 - val_loss: 8.3053 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1500\n",
      "168/168 [==============================] - 0s 854us/step - loss: 1.6879 - acc: 0.3690 - val_loss: 8.4199 - val_acc: 0.0000e+00\n",
      "Epoch 60/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 1.6695 - acc: 0.3690 - val_loss: 8.5647 - val_acc: 0.0000e+00\n",
      "Epoch 61/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 1.6532 - acc: 0.3393 - val_loss: 8.7197 - val_acc: 0.0000e+00\n",
      "Epoch 62/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 1.6617 - acc: 0.3929 - val_loss: 8.8694 - val_acc: 0.0000e+00\n",
      "Epoch 63/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 1.6377 - acc: 0.3690 - val_loss: 9.0224 - val_acc: 0.0000e+00\n",
      "Epoch 64/1500\n",
      "168/168 [==============================] - 0s 800us/step - loss: 1.6381 - acc: 0.3810 - val_loss: 9.1575 - val_acc: 0.0000e+00\n",
      "Epoch 65/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 1.6079 - acc: 0.3810 - val_loss: 9.2787 - val_acc: 0.0000e+00\n",
      "Epoch 66/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 1.5606 - acc: 0.4167 - val_loss: 9.4127 - val_acc: 0.0000e+00\n",
      "Epoch 67/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 1.5989 - acc: 0.4286 - val_loss: 9.4888 - val_acc: 0.0000e+00\n",
      "Epoch 68/1500\n",
      "168/168 [==============================] - 0s 854us/step - loss: 1.5489 - acc: 0.3571 - val_loss: 9.5709 - val_acc: 0.0000e+00\n",
      "Epoch 69/1500\n",
      "168/168 [==============================] - 0s 854us/step - loss: 1.5428 - acc: 0.4702 - val_loss: 9.6519 - val_acc: 0.0000e+00\n",
      "Epoch 70/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 1.5373 - acc: 0.3988 - val_loss: 9.7184 - val_acc: 0.0000e+00\n",
      "Epoch 71/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 1.4955 - acc: 0.4286 - val_loss: 9.8040 - val_acc: 0.0000e+00\n",
      "Epoch 72/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 1.4604 - acc: 0.4702 - val_loss: 9.9104 - val_acc: 0.0000e+00\n",
      "Epoch 73/1500\n",
      "168/168 [==============================] - 0s 817us/step - loss: 1.4716 - acc: 0.4702 - val_loss: 10.0199 - val_acc: 0.0000e+00\n",
      "Epoch 74/1500\n",
      "168/168 [==============================] - 0s 855us/step - loss: 1.4393 - acc: 0.4940 - val_loss: 10.1392 - val_acc: 0.0000e+00\n",
      "Epoch 75/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 1.4437 - acc: 0.4643 - val_loss: 10.2612 - val_acc: 0.0000e+00\n",
      "Epoch 76/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 1.4164 - acc: 0.4048 - val_loss: 10.3706 - val_acc: 0.0000e+00\n",
      "Epoch 77/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 1.3786 - acc: 0.5179 - val_loss: 10.4867 - val_acc: 0.0000e+00\n",
      "Epoch 78/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 1.3556 - acc: 0.5893 - val_loss: 10.6097 - val_acc: 0.0000e+00\n",
      "Epoch 79/1500\n",
      "168/168 [==============================] - 0s 816us/step - loss: 1.3183 - acc: 0.5298 - val_loss: 10.7193 - val_acc: 0.0000e+00\n",
      "Epoch 80/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 1.3035 - acc: 0.5833 - val_loss: 10.7944 - val_acc: 0.0000e+00\n",
      "Epoch 81/1500\n",
      "168/168 [==============================] - 0s 854us/step - loss: 1.3086 - acc: 0.5655 - val_loss: 10.8508 - val_acc: 0.0000e+00\n",
      "Epoch 82/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 1.2862 - acc: 0.5357 - val_loss: 10.9203 - val_acc: 0.0000e+00\n",
      "Epoch 83/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 1.2107 - acc: 0.6071 - val_loss: 10.9901 - val_acc: 0.0000e+00\n",
      "Epoch 84/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 1.2181 - acc: 0.6131 - val_loss: 11.0568 - val_acc: 0.0000e+00\n",
      "Epoch 85/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 1.2173 - acc: 0.5893 - val_loss: 11.1226 - val_acc: 0.0000e+00\n",
      "Epoch 86/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 1.1916 - acc: 0.6012 - val_loss: 11.2038 - val_acc: 0.0000e+00\n",
      "Epoch 87/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 1.1554 - acc: 0.6071 - val_loss: 11.3029 - val_acc: 0.0000e+00\n",
      "Epoch 88/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 1.1714 - acc: 0.5952 - val_loss: 11.3902 - val_acc: 0.0000e+00\n",
      "Epoch 89/1500\n",
      "168/168 [==============================] - 0s 859us/step - loss: 1.1263 - acc: 0.6429 - val_loss: 11.4745 - val_acc: 0.0000e+00\n",
      "Epoch 90/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 1.1218 - acc: 0.6131 - val_loss: 11.5427 - val_acc: 0.0000e+00\n",
      "Epoch 91/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 1.0684 - acc: 0.6429 - val_loss: 11.6030 - val_acc: 0.0000e+00\n",
      "Epoch 92/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 1.1079 - acc: 0.6488 - val_loss: 11.6524 - val_acc: 0.0000e+00\n",
      "Epoch 93/1500\n",
      "168/168 [==============================] - 0s 861us/step - loss: 1.0526 - acc: 0.6667 - val_loss: 11.7124 - val_acc: 0.0000e+00\n",
      "Epoch 94/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 1.0137 - acc: 0.7143 - val_loss: 11.7677 - val_acc: 0.0000e+00\n",
      "Epoch 95/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 1.0383 - acc: 0.6845 - val_loss: 11.8317 - val_acc: 0.0000e+00\n",
      "Epoch 96/1500\n",
      "168/168 [==============================] - 0s 809us/step - loss: 0.9691 - acc: 0.6905 - val_loss: 11.9219 - val_acc: 0.0000e+00\n",
      "Epoch 97/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.9431 - acc: 0.7143 - val_loss: 12.0341 - val_acc: 0.0000e+00\n",
      "Epoch 98/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.9683 - acc: 0.6607 - val_loss: 12.1294 - val_acc: 0.0000e+00\n",
      "Epoch 99/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.9637 - acc: 0.7024 - val_loss: 12.1552 - val_acc: 0.0000e+00\n",
      "Epoch 100/1500\n",
      "168/168 [==============================] - 0s 810us/step - loss: 0.9184 - acc: 0.6905 - val_loss: 12.1426 - val_acc: 0.0000e+00\n",
      "Epoch 101/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.8882 - acc: 0.7738 - val_loss: 12.1698 - val_acc: 0.0000e+00\n",
      "Epoch 102/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.8555 - acc: 0.7798 - val_loss: 12.2162 - val_acc: 0.0000e+00\n",
      "Epoch 103/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.8976 - acc: 0.6905 - val_loss: 12.3038 - val_acc: 0.0000e+00\n",
      "Epoch 104/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.8517 - acc: 0.7738 - val_loss: 12.4141 - val_acc: 0.0000e+00\n",
      "Epoch 105/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.8065 - acc: 0.7560 - val_loss: 12.5236 - val_acc: 0.0000e+00\n",
      "Epoch 106/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.8796 - acc: 0.6964 - val_loss: 12.5866 - val_acc: 0.0000e+00\n",
      "Epoch 107/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.8821 - acc: 0.7202 - val_loss: 12.6199 - val_acc: 0.0000e+00\n",
      "Epoch 108/1500\n",
      "168/168 [==============================] - 0s 855us/step - loss: 0.8348 - acc: 0.7500 - val_loss: 12.6331 - val_acc: 0.0000e+00\n",
      "Epoch 109/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.7923 - acc: 0.7619 - val_loss: 12.6271 - val_acc: 0.0000e+00\n",
      "Epoch 110/1500\n",
      "168/168 [==============================] - 0s 853us/step - loss: 0.7019 - acc: 0.7976 - val_loss: 12.6664 - val_acc: 0.0000e+00\n",
      "Epoch 111/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.7574 - acc: 0.7500 - val_loss: 12.7303 - val_acc: 0.0000e+00\n",
      "Epoch 112/1500\n",
      "168/168 [==============================] - 0s 856us/step - loss: 0.7320 - acc: 0.8393 - val_loss: 12.8143 - val_acc: 0.0000e+00\n",
      "Epoch 113/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.7462 - acc: 0.8036 - val_loss: 12.9015 - val_acc: 0.0000e+00\n",
      "Epoch 114/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.7049 - acc: 0.8095 - val_loss: 12.9725 - val_acc: 0.0000e+00\n",
      "Epoch 115/1500\n",
      "168/168 [==============================] - 0s 816us/step - loss: 0.7173 - acc: 0.7738 - val_loss: 13.0104 - val_acc: 0.0000e+00\n",
      "Epoch 116/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.6649 - acc: 0.8274 - val_loss: 13.0344 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/1500\n",
      "168/168 [==============================] - 0s 813us/step - loss: 0.6658 - acc: 0.7976 - val_loss: 13.0345 - val_acc: 0.0000e+00\n",
      "Epoch 118/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.6337 - acc: 0.8512 - val_loss: 13.0446 - val_acc: 0.0000e+00\n",
      "Epoch 119/1500\n",
      "168/168 [==============================] - 0s 871us/step - loss: 0.6384 - acc: 0.8274 - val_loss: 13.1068 - val_acc: 0.0000e+00\n",
      "Epoch 120/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.6598 - acc: 0.8333 - val_loss: 13.1695 - val_acc: 0.0000e+00\n",
      "Epoch 121/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.6665 - acc: 0.8036 - val_loss: 13.2376 - val_acc: 0.0000e+00\n",
      "Epoch 122/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.6398 - acc: 0.7976 - val_loss: 13.2926 - val_acc: 0.0000e+00\n",
      "Epoch 123/1500\n",
      "168/168 [==============================] - 0s 852us/step - loss: 0.6273 - acc: 0.8214 - val_loss: 13.3351 - val_acc: 0.0000e+00\n",
      "Epoch 124/1500\n",
      "168/168 [==============================] - 0s 856us/step - loss: 0.6260 - acc: 0.7798 - val_loss: 13.3538 - val_acc: 0.0000e+00\n",
      "Epoch 125/1500\n",
      "168/168 [==============================] - 0s 855us/step - loss: 0.6686 - acc: 0.7857 - val_loss: 13.3592 - val_acc: 0.0000e+00\n",
      "Epoch 126/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.6184 - acc: 0.8036 - val_loss: 13.3622 - val_acc: 0.0000e+00\n",
      "Epoch 127/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.5196 - acc: 0.8631 - val_loss: 13.4006 - val_acc: 0.0000e+00\n",
      "Epoch 128/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.5657 - acc: 0.8036 - val_loss: 13.4391 - val_acc: 0.0000e+00\n",
      "Epoch 129/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.5774 - acc: 0.8333 - val_loss: 13.4969 - val_acc: 0.0000e+00\n",
      "Epoch 130/1500\n",
      "168/168 [==============================] - 0s 817us/step - loss: 0.5669 - acc: 0.8274 - val_loss: 13.5757 - val_acc: 0.0000e+00\n",
      "Epoch 131/1500\n",
      "168/168 [==============================] - 0s 814us/step - loss: 0.5329 - acc: 0.8393 - val_loss: 13.6680 - val_acc: 0.0000e+00\n",
      "Epoch 132/1500\n",
      "168/168 [==============================] - 0s 859us/step - loss: 0.5585 - acc: 0.8155 - val_loss: 13.7126 - val_acc: 0.0000e+00\n",
      "Epoch 133/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.5070 - acc: 0.8571 - val_loss: 13.7605 - val_acc: 0.0000e+00\n",
      "Epoch 134/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.5166 - acc: 0.8393 - val_loss: 13.7566 - val_acc: 0.0000e+00\n",
      "Epoch 135/1500\n",
      "168/168 [==============================] - 0s 810us/step - loss: 0.5558 - acc: 0.8274 - val_loss: 13.7754 - val_acc: 0.0000e+00\n",
      "Epoch 136/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.5298 - acc: 0.8333 - val_loss: 13.8301 - val_acc: 0.0000e+00\n",
      "Epoch 137/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.4436 - acc: 0.8869 - val_loss: 13.9203 - val_acc: 0.0000e+00\n",
      "Epoch 138/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.5006 - acc: 0.8393 - val_loss: 14.0003 - val_acc: 0.0000e+00\n",
      "Epoch 139/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.4259 - acc: 0.8810 - val_loss: 14.0900 - val_acc: 0.0000e+00\n",
      "Epoch 140/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.5027 - acc: 0.8393 - val_loss: 14.1145 - val_acc: 0.0000e+00\n",
      "Epoch 141/1500\n",
      "168/168 [==============================] - 0s 805us/step - loss: 0.4497 - acc: 0.8869 - val_loss: 14.1344 - val_acc: 0.0000e+00\n",
      "Epoch 142/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.4351 - acc: 0.9048 - val_loss: 14.1351 - val_acc: 0.0000e+00\n",
      "Epoch 143/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.4567 - acc: 0.8512 - val_loss: 14.1150 - val_acc: 0.0000e+00\n",
      "Epoch 144/1500\n",
      "168/168 [==============================] - 0s 814us/step - loss: 0.3745 - acc: 0.9286 - val_loss: 14.1298 - val_acc: 0.0000e+00\n",
      "Epoch 145/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.4896 - acc: 0.8274 - val_loss: 14.1949 - val_acc: 0.0000e+00\n",
      "Epoch 146/1500\n",
      "168/168 [==============================] - 0s 811us/step - loss: 0.4963 - acc: 0.8452 - val_loss: 14.3035 - val_acc: 0.0000e+00\n",
      "Epoch 147/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.4942 - acc: 0.8214 - val_loss: 14.4125 - val_acc: 0.0000e+00\n",
      "Epoch 148/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.4399 - acc: 0.8571 - val_loss: 14.4781 - val_acc: 0.0000e+00\n",
      "Epoch 149/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.4103 - acc: 0.8810 - val_loss: 14.5191 - val_acc: 0.0000e+00\n",
      "Epoch 150/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.4537 - acc: 0.8512 - val_loss: 14.5031 - val_acc: 0.0000e+00\n",
      "Epoch 151/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.4539 - acc: 0.8631 - val_loss: 14.4740 - val_acc: 0.0000e+00\n",
      "Epoch 152/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.3687 - acc: 0.9048 - val_loss: 14.4769 - val_acc: 0.0000e+00\n",
      "Epoch 153/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 0.4506 - acc: 0.8452 - val_loss: 14.4775 - val_acc: 0.0000e+00\n",
      "Epoch 154/1500\n",
      "168/168 [==============================] - 0s 817us/step - loss: 0.3678 - acc: 0.8810 - val_loss: 14.5381 - val_acc: 0.0000e+00\n",
      "Epoch 155/1500\n",
      "168/168 [==============================] - 0s 813us/step - loss: 0.4798 - acc: 0.8095 - val_loss: 14.6148 - val_acc: 0.0000e+00\n",
      "Epoch 156/1500\n",
      "168/168 [==============================] - 0s 813us/step - loss: 0.4548 - acc: 0.8690 - val_loss: 14.7228 - val_acc: 0.0000e+00\n",
      "Epoch 157/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.4550 - acc: 0.8571 - val_loss: 14.7892 - val_acc: 0.0000e+00\n",
      "Epoch 158/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.5510 - acc: 0.8571 - val_loss: 14.7872 - val_acc: 0.0000e+00\n",
      "Epoch 159/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.4153 - acc: 0.8690 - val_loss: 14.7699 - val_acc: 0.0000e+00\n",
      "Epoch 160/1500\n",
      "168/168 [==============================] - 0s 861us/step - loss: 0.3556 - acc: 0.8869 - val_loss: 14.7205 - val_acc: 0.0000e+00\n",
      "Epoch 161/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.5296 - acc: 0.8095 - val_loss: 14.6436 - val_acc: 0.0000e+00\n",
      "Epoch 162/1500\n",
      "168/168 [==============================] - 0s 864us/step - loss: 0.3475 - acc: 0.8988 - val_loss: 14.6301 - val_acc: 0.0000e+00\n",
      "Epoch 163/1500\n",
      "168/168 [==============================] - 0s 812us/step - loss: 0.5086 - acc: 0.8810 - val_loss: 14.6324 - val_acc: 0.0000e+00\n",
      "Epoch 164/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.3881 - acc: 0.8690 - val_loss: 14.6806 - val_acc: 0.0000e+00\n",
      "Epoch 165/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.3686 - acc: 0.8869 - val_loss: 14.7181 - val_acc: 0.0000e+00\n",
      "Epoch 166/1500\n",
      "168/168 [==============================] - 0s 876us/step - loss: 0.4179 - acc: 0.8988 - val_loss: 14.7481 - val_acc: 0.0000e+00\n",
      "Epoch 167/1500\n",
      "168/168 [==============================] - 0s 855us/step - loss: 0.4103 - acc: 0.8750 - val_loss: 14.7971 - val_acc: 0.0000e+00\n",
      "Epoch 168/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.4828 - acc: 0.8274 - val_loss: 14.8116 - val_acc: 0.0000e+00\n",
      "Epoch 169/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.3794 - acc: 0.9167 - val_loss: 14.8249 - val_acc: 0.0000e+00\n",
      "Epoch 170/1500\n",
      "168/168 [==============================] - 0s 812us/step - loss: 0.3709 - acc: 0.9048 - val_loss: 14.8579 - val_acc: 0.0000e+00\n",
      "Epoch 171/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.3320 - acc: 0.8988 - val_loss: 14.8918 - val_acc: 0.0000e+00\n",
      "Epoch 172/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.3599 - acc: 0.8810 - val_loss: 14.9365 - val_acc: 0.0000e+00\n",
      "Epoch 173/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.3447 - acc: 0.8988 - val_loss: 14.9760 - val_acc: 0.0000e+00\n",
      "Epoch 174/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.3418 - acc: 0.9167 - val_loss: 14.9835 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/1500\n",
      "168/168 [==============================] - 0s 815us/step - loss: 0.3533 - acc: 0.8929 - val_loss: 14.9930 - val_acc: 0.0000e+00\n",
      "Epoch 176/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.3156 - acc: 0.9167 - val_loss: 15.0401 - val_acc: 0.0000e+00\n",
      "Epoch 177/1500\n",
      "168/168 [==============================] - 0s 813us/step - loss: 0.3883 - acc: 0.8452 - val_loss: 15.0788 - val_acc: 0.0000e+00\n",
      "Epoch 178/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.3645 - acc: 0.9107 - val_loss: 15.0850 - val_acc: 0.0000e+00\n",
      "Epoch 179/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.4095 - acc: 0.8929 - val_loss: 15.0756 - val_acc: 0.0000e+00\n",
      "Epoch 180/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.4058 - acc: 0.8929 - val_loss: 15.0723 - val_acc: 0.0000e+00\n",
      "Epoch 181/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.3344 - acc: 0.8929 - val_loss: 15.0649 - val_acc: 0.0000e+00\n",
      "Epoch 182/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.3536 - acc: 0.9167 - val_loss: 15.0567 - val_acc: 0.0000e+00\n",
      "Epoch 183/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.4094 - acc: 0.8690 - val_loss: 15.0207 - val_acc: 0.0000e+00\n",
      "Epoch 184/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.3344 - acc: 0.8988 - val_loss: 15.0219 - val_acc: 0.0000e+00\n",
      "Epoch 185/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.3702 - acc: 0.8869 - val_loss: 15.0273 - val_acc: 0.0000e+00\n",
      "Epoch 186/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 0.3744 - acc: 0.8750 - val_loss: 15.0514 - val_acc: 0.0000e+00\n",
      "Epoch 187/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.3225 - acc: 0.8988 - val_loss: 15.0505 - val_acc: 0.0000e+00\n",
      "Epoch 188/1500\n",
      "168/168 [==============================] - 0s 813us/step - loss: 0.2919 - acc: 0.9167 - val_loss: 15.0402 - val_acc: 0.0000e+00\n",
      "Epoch 189/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.2865 - acc: 0.9286 - val_loss: 15.0503 - val_acc: 0.0000e+00\n",
      "Epoch 190/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.2859 - acc: 0.9286 - val_loss: 15.0499 - val_acc: 0.0000e+00\n",
      "Epoch 191/1500\n",
      "168/168 [==============================] - 0s 820us/step - loss: 0.3247 - acc: 0.9107 - val_loss: 15.0383 - val_acc: 0.0000e+00\n",
      "Epoch 192/1500\n",
      "168/168 [==============================] - 0s 820us/step - loss: 0.3013 - acc: 0.9286 - val_loss: 15.0376 - val_acc: 0.0000e+00\n",
      "Epoch 193/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.2967 - acc: 0.9048 - val_loss: 15.0740 - val_acc: 0.0000e+00\n",
      "Epoch 194/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.3471 - acc: 0.8988 - val_loss: 15.1234 - val_acc: 0.0000e+00\n",
      "Epoch 195/1500\n",
      "168/168 [==============================] - 0s 809us/step - loss: 0.3303 - acc: 0.9048 - val_loss: 15.1639 - val_acc: 0.0000e+00\n",
      "Epoch 196/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.3492 - acc: 0.8810 - val_loss: 15.2051 - val_acc: 0.0000e+00\n",
      "Epoch 197/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.3271 - acc: 0.8929 - val_loss: 15.2881 - val_acc: 0.0000e+00\n",
      "Epoch 198/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.2692 - acc: 0.9286 - val_loss: 15.3531 - val_acc: 0.0000e+00\n",
      "Epoch 199/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.3155 - acc: 0.8869 - val_loss: 15.3806 - val_acc: 0.0000e+00\n",
      "Epoch 200/1500\n",
      "168/168 [==============================] - 0s 812us/step - loss: 0.2958 - acc: 0.9345 - val_loss: 15.3856 - val_acc: 0.0000e+00\n",
      "Epoch 201/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.3060 - acc: 0.8988 - val_loss: 15.3593 - val_acc: 0.0000e+00\n",
      "Epoch 202/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.4126 - acc: 0.8512 - val_loss: 15.2549 - val_acc: 0.0000e+00\n",
      "Epoch 203/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.2944 - acc: 0.9226 - val_loss: 15.1741 - val_acc: 0.0000e+00\n",
      "Epoch 204/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.3457 - acc: 0.8929 - val_loss: 15.1434 - val_acc: 0.0000e+00\n",
      "Epoch 205/1500\n",
      "168/168 [==============================] - 0s 801us/step - loss: 0.3076 - acc: 0.8988 - val_loss: 15.1695 - val_acc: 0.0000e+00\n",
      "Epoch 206/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.2952 - acc: 0.9226 - val_loss: 15.2250 - val_acc: 0.0000e+00\n",
      "Epoch 207/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.3031 - acc: 0.8810 - val_loss: 15.2490 - val_acc: 0.0000e+00\n",
      "Epoch 208/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.2674 - acc: 0.9286 - val_loss: 15.2735 - val_acc: 0.0000e+00\n",
      "Epoch 209/1500\n",
      "168/168 [==============================] - 0s 820us/step - loss: 0.2713 - acc: 0.9286 - val_loss: 15.2942 - val_acc: 0.0000e+00\n",
      "Epoch 210/1500\n",
      "168/168 [==============================] - 0s 808us/step - loss: 0.2346 - acc: 0.9345 - val_loss: 15.3000 - val_acc: 0.0000e+00\n",
      "Epoch 211/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.3737 - acc: 0.9226 - val_loss: 15.2980 - val_acc: 0.0000e+00\n",
      "Epoch 212/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.2660 - acc: 0.9226 - val_loss: 15.3049 - val_acc: 0.0000e+00\n",
      "Epoch 213/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.2726 - acc: 0.9048 - val_loss: 15.3105 - val_acc: 0.0000e+00\n",
      "Epoch 214/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.2718 - acc: 0.9226 - val_loss: 15.3132 - val_acc: 0.0000e+00\n",
      "Epoch 215/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.2243 - acc: 0.9345 - val_loss: 15.3322 - val_acc: 0.0000e+00\n",
      "Epoch 216/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.2594 - acc: 0.9464 - val_loss: 15.3798 - val_acc: 0.0000e+00\n",
      "Epoch 217/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.3035 - acc: 0.9405 - val_loss: 15.4282 - val_acc: 0.0000e+00\n",
      "Epoch 218/1500\n",
      "168/168 [==============================] - 0s 812us/step - loss: 0.2303 - acc: 0.9286 - val_loss: 15.4938 - val_acc: 0.0000e+00\n",
      "Epoch 219/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.2177 - acc: 0.9286 - val_loss: 15.5561 - val_acc: 0.0000e+00\n",
      "Epoch 220/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.2464 - acc: 0.9226 - val_loss: 15.5851 - val_acc: 0.0000e+00\n",
      "Epoch 221/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.2107 - acc: 0.9524 - val_loss: 15.5926 - val_acc: 0.0000e+00\n",
      "Epoch 222/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.3321 - acc: 0.8690 - val_loss: 15.5683 - val_acc: 0.0000e+00\n",
      "Epoch 223/1500\n",
      "168/168 [==============================] - 0s 799us/step - loss: 0.2290 - acc: 0.9405 - val_loss: 15.5353 - val_acc: 0.0000e+00\n",
      "Epoch 224/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.2900 - acc: 0.9167 - val_loss: 15.4698 - val_acc: 0.0000e+00\n",
      "Epoch 225/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.2438 - acc: 0.9107 - val_loss: 15.4402 - val_acc: 0.0000e+00\n",
      "Epoch 226/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.1904 - acc: 0.9524 - val_loss: 15.4427 - val_acc: 0.0000e+00\n",
      "Epoch 227/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.2452 - acc: 0.9286 - val_loss: 15.4731 - val_acc: 0.0000e+00\n",
      "Epoch 228/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.2165 - acc: 0.9345 - val_loss: 15.5308 - val_acc: 0.0000e+00\n",
      "Epoch 229/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.2200 - acc: 0.9524 - val_loss: 15.5868 - val_acc: 0.0000e+00\n",
      "Epoch 230/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.2435 - acc: 0.9345 - val_loss: 15.6316 - val_acc: 0.0000e+00\n",
      "Epoch 231/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.1918 - acc: 0.9345 - val_loss: 15.6716 - val_acc: 0.0000e+00\n",
      "Epoch 232/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.2272 - acc: 0.9286 - val_loss: 15.6841 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/1500\n",
      "168/168 [==============================] - 0s 880us/step - loss: 0.2364 - acc: 0.9226 - val_loss: 15.6718 - val_acc: 0.0000e+00\n",
      "Epoch 234/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.2398 - acc: 0.9345 - val_loss: 15.6406 - val_acc: 0.0000e+00\n",
      "Epoch 235/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.1602 - acc: 0.9702 - val_loss: 15.6201 - val_acc: 0.0000e+00\n",
      "Epoch 236/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.2505 - acc: 0.9107 - val_loss: 15.6099 - val_acc: 0.0000e+00\n",
      "Epoch 237/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.2118 - acc: 0.9524 - val_loss: 15.6309 - val_acc: 0.0000e+00\n",
      "Epoch 238/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.2623 - acc: 0.9464 - val_loss: 15.6635 - val_acc: 0.0000e+00\n",
      "Epoch 239/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.2481 - acc: 0.9226 - val_loss: 15.6920 - val_acc: 0.0000e+00\n",
      "Epoch 240/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.2457 - acc: 0.9226 - val_loss: 15.7366 - val_acc: 0.0000e+00\n",
      "Epoch 241/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.3462 - acc: 0.9048 - val_loss: 15.7548 - val_acc: 0.0000e+00\n",
      "Epoch 242/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.2203 - acc: 0.9464 - val_loss: 15.7661 - val_acc: 0.0000e+00\n",
      "Epoch 243/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.2373 - acc: 0.9226 - val_loss: 15.7751 - val_acc: 0.0000e+00\n",
      "Epoch 244/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.1711 - acc: 0.9583 - val_loss: 15.7724 - val_acc: 0.0000e+00\n",
      "Epoch 245/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.2247 - acc: 0.9345 - val_loss: 15.7589 - val_acc: 0.0000e+00\n",
      "Epoch 246/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.1628 - acc: 0.9643 - val_loss: 15.7529 - val_acc: 0.0000e+00\n",
      "Epoch 247/1500\n",
      "168/168 [==============================] - 0s 820us/step - loss: 0.1961 - acc: 0.9226 - val_loss: 15.7283 - val_acc: 0.0000e+00\n",
      "Epoch 248/1500\n",
      "168/168 [==============================] - 0s 857us/step - loss: 0.2502 - acc: 0.9345 - val_loss: 15.6938 - val_acc: 0.0000e+00\n",
      "Epoch 249/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.2027 - acc: 0.9405 - val_loss: 15.6576 - val_acc: 0.0000e+00\n",
      "Epoch 250/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.2036 - acc: 0.9464 - val_loss: 15.6700 - val_acc: 0.0000e+00\n",
      "Epoch 251/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.2075 - acc: 0.9464 - val_loss: 15.6892 - val_acc: 0.0000e+00\n",
      "Epoch 252/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.2596 - acc: 0.9226 - val_loss: 15.7042 - val_acc: 0.0000e+00\n",
      "Epoch 253/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.2020 - acc: 0.9405 - val_loss: 15.7268 - val_acc: 0.0000e+00\n",
      "Epoch 254/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.2120 - acc: 0.9405 - val_loss: 15.7505 - val_acc: 0.0000e+00\n",
      "Epoch 255/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.2862 - acc: 0.9345 - val_loss: 15.7533 - val_acc: 0.0000e+00\n",
      "Epoch 256/1500\n",
      "168/168 [==============================] - 0s 867us/step - loss: 0.1998 - acc: 0.9524 - val_loss: 15.7447 - val_acc: 0.0000e+00\n",
      "Epoch 257/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.1565 - acc: 0.9702 - val_loss: 15.7259 - val_acc: 0.0000e+00\n",
      "Epoch 258/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.2570 - acc: 0.8988 - val_loss: 15.7113 - val_acc: 0.0000e+00\n",
      "Epoch 259/1500\n",
      "168/168 [==============================] - 0s 814us/step - loss: 0.1942 - acc: 0.9464 - val_loss: 15.7100 - val_acc: 0.0000e+00\n",
      "Epoch 260/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.1939 - acc: 0.9405 - val_loss: 15.7226 - val_acc: 0.0000e+00\n",
      "Epoch 261/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.2360 - acc: 0.9345 - val_loss: 15.7318 - val_acc: 0.0000e+00\n",
      "Epoch 262/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.2263 - acc: 0.9405 - val_loss: 15.7301 - val_acc: 0.0000e+00\n",
      "Epoch 263/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.1493 - acc: 0.9583 - val_loss: 15.7290 - val_acc: 0.0000e+00\n",
      "Epoch 264/1500\n",
      "168/168 [==============================] - 0s 817us/step - loss: 0.1670 - acc: 0.9405 - val_loss: 15.7305 - val_acc: 0.0000e+00\n",
      "Epoch 265/1500\n",
      "168/168 [==============================] - 0s 859us/step - loss: 0.2197 - acc: 0.9345 - val_loss: 15.7372 - val_acc: 0.0000e+00\n",
      "Epoch 266/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.2125 - acc: 0.9405 - val_loss: 15.7517 - val_acc: 0.0000e+00\n",
      "Epoch 267/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.2165 - acc: 0.9286 - val_loss: 15.7634 - val_acc: 0.0000e+00\n",
      "Epoch 268/1500\n",
      "168/168 [==============================] - 0s 812us/step - loss: 0.2156 - acc: 0.9286 - val_loss: 15.7544 - val_acc: 0.0000e+00\n",
      "Epoch 269/1500\n",
      "168/168 [==============================] - 0s 817us/step - loss: 0.1571 - acc: 0.9524 - val_loss: 15.7455 - val_acc: 0.0000e+00\n",
      "Epoch 270/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.1551 - acc: 0.9643 - val_loss: 15.7340 - val_acc: 0.0000e+00\n",
      "Epoch 271/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.1941 - acc: 0.9524 - val_loss: 15.7230 - val_acc: 0.0000e+00\n",
      "Epoch 272/1500\n",
      "168/168 [==============================] - 0s 800us/step - loss: 0.1567 - acc: 0.9524 - val_loss: 15.7294 - val_acc: 0.0000e+00\n",
      "Epoch 273/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.1635 - acc: 0.9583 - val_loss: 15.7445 - val_acc: 0.0000e+00\n",
      "Epoch 274/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.1853 - acc: 0.9464 - val_loss: 15.7438 - val_acc: 0.0000e+00\n",
      "Epoch 275/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.1616 - acc: 0.9643 - val_loss: 15.7500 - val_acc: 0.0000e+00\n",
      "Epoch 276/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.1541 - acc: 0.9583 - val_loss: 15.7682 - val_acc: 0.0000e+00\n",
      "Epoch 277/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.2229 - acc: 0.9345 - val_loss: 15.7822 - val_acc: 0.0000e+00\n",
      "Epoch 278/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.1605 - acc: 0.9524 - val_loss: 15.7963 - val_acc: 0.0000e+00\n",
      "Epoch 279/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.2642 - acc: 0.9345 - val_loss: 15.8025 - val_acc: 0.0000e+00\n",
      "Epoch 280/1500\n",
      "168/168 [==============================] - 0s 864us/step - loss: 0.1822 - acc: 0.9583 - val_loss: 15.8134 - val_acc: 0.0000e+00\n",
      "Epoch 281/1500\n",
      "168/168 [==============================] - 0s 795us/step - loss: 0.1840 - acc: 0.9405 - val_loss: 15.8031 - val_acc: 0.0000e+00\n",
      "Epoch 282/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.1754 - acc: 0.9643 - val_loss: 15.7997 - val_acc: 0.0000e+00\n",
      "Epoch 283/1500\n",
      "168/168 [==============================] - 0s 820us/step - loss: 0.1731 - acc: 0.9524 - val_loss: 15.8121 - val_acc: 0.0000e+00\n",
      "Epoch 284/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.1762 - acc: 0.9643 - val_loss: 15.8162 - val_acc: 0.0000e+00\n",
      "Epoch 285/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.1654 - acc: 0.9524 - val_loss: 15.8131 - val_acc: 0.0000e+00\n",
      "Epoch 286/1500\n",
      "168/168 [==============================] - 0s 815us/step - loss: 0.1447 - acc: 0.9762 - val_loss: 15.8180 - val_acc: 0.0000e+00\n",
      "Epoch 287/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.2029 - acc: 0.9524 - val_loss: 15.8211 - val_acc: 0.0000e+00\n",
      "Epoch 288/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.1410 - acc: 0.9583 - val_loss: 15.8413 - val_acc: 0.0000e+00\n",
      "Epoch 289/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.2315 - acc: 0.9167 - val_loss: 15.8715 - val_acc: 0.0000e+00\n",
      "Epoch 290/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.1650 - acc: 0.9524 - val_loss: 15.8932 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.1727 - acc: 0.9643 - val_loss: 15.8984 - val_acc: 0.0000e+00\n",
      "Epoch 292/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.1879 - acc: 0.9345 - val_loss: 15.8824 - val_acc: 0.0000e+00\n",
      "Epoch 293/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.2313 - acc: 0.9167 - val_loss: 15.8643 - val_acc: 0.0000e+00\n",
      "Epoch 294/1500\n",
      "168/168 [==============================] - 0s 857us/step - loss: 0.0988 - acc: 0.9821 - val_loss: 15.8465 - val_acc: 0.0000e+00\n",
      "Epoch 295/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.1448 - acc: 0.9583 - val_loss: 15.8251 - val_acc: 0.0000e+00\n",
      "Epoch 296/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.1604 - acc: 0.9643 - val_loss: 15.8274 - val_acc: 0.0000e+00\n",
      "Epoch 297/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.1756 - acc: 0.9524 - val_loss: 15.8442 - val_acc: 0.0000e+00\n",
      "Epoch 298/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.1901 - acc: 0.9286 - val_loss: 15.8571 - val_acc: 0.0000e+00\n",
      "Epoch 299/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.2132 - acc: 0.9464 - val_loss: 15.8784 - val_acc: 0.0000e+00\n",
      "Epoch 300/1500\n",
      "168/168 [==============================] - 0s 817us/step - loss: 0.1186 - acc: 0.9821 - val_loss: 15.8973 - val_acc: 0.0000e+00\n",
      "Epoch 301/1500\n",
      "168/168 [==============================] - 0s 817us/step - loss: 0.1862 - acc: 0.9464 - val_loss: 15.9064 - val_acc: 0.0000e+00\n",
      "Epoch 302/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.1401 - acc: 0.9643 - val_loss: 15.9174 - val_acc: 0.0000e+00\n",
      "Epoch 303/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.1413 - acc: 0.9524 - val_loss: 15.9230 - val_acc: 0.0000e+00\n",
      "Epoch 304/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 0.2240 - acc: 0.9524 - val_loss: 15.9286 - val_acc: 0.0000e+00\n",
      "Epoch 305/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.1380 - acc: 0.9702 - val_loss: 15.9325 - val_acc: 0.0000e+00\n",
      "Epoch 306/1500\n",
      "168/168 [==============================] - 0s 820us/step - loss: 0.1581 - acc: 0.9643 - val_loss: 15.9295 - val_acc: 0.0000e+00\n",
      "Epoch 307/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.1071 - acc: 0.9762 - val_loss: 15.9287 - val_acc: 0.0000e+00\n",
      "Epoch 308/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.1592 - acc: 0.9583 - val_loss: 15.9264 - val_acc: 0.0000e+00\n",
      "Epoch 309/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.1397 - acc: 0.9702 - val_loss: 15.9245 - val_acc: 0.0000e+00\n",
      "Epoch 310/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.1307 - acc: 0.9702 - val_loss: 15.9240 - val_acc: 0.0000e+00\n",
      "Epoch 311/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.1862 - acc: 0.9583 - val_loss: 15.9220 - val_acc: 0.0000e+00\n",
      "Epoch 312/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.1516 - acc: 0.9643 - val_loss: 15.9267 - val_acc: 0.0000e+00\n",
      "Epoch 313/1500\n",
      "168/168 [==============================] - 0s 866us/step - loss: 0.1528 - acc: 0.9583 - val_loss: 15.9294 - val_acc: 0.0000e+00\n",
      "Epoch 314/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.1349 - acc: 0.9524 - val_loss: 15.9321 - val_acc: 0.0000e+00\n",
      "Epoch 315/1500\n",
      "168/168 [==============================] - 0s 864us/step - loss: 0.1294 - acc: 0.9524 - val_loss: 15.9362 - val_acc: 0.0000e+00\n",
      "Epoch 316/1500\n",
      "168/168 [==============================] - 0s 803us/step - loss: 0.1723 - acc: 0.9405 - val_loss: 15.9344 - val_acc: 0.0000e+00\n",
      "Epoch 317/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.1002 - acc: 0.9702 - val_loss: 15.9288 - val_acc: 0.0000e+00\n",
      "Epoch 318/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.1768 - acc: 0.9583 - val_loss: 15.9066 - val_acc: 0.0000e+00\n",
      "Epoch 319/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.1489 - acc: 0.9524 - val_loss: 15.9038 - val_acc: 0.0000e+00\n",
      "Epoch 320/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.1083 - acc: 0.9702 - val_loss: 15.9065 - val_acc: 0.0000e+00\n",
      "Epoch 321/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.1197 - acc: 0.9643 - val_loss: 15.9186 - val_acc: 0.0000e+00\n",
      "Epoch 322/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.1330 - acc: 0.9524 - val_loss: 15.9255 - val_acc: 0.0000e+00\n",
      "Epoch 323/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.1017 - acc: 0.9940 - val_loss: 15.9358 - val_acc: 0.0000e+00\n",
      "Epoch 324/1500\n",
      "168/168 [==============================] - 0s 816us/step - loss: 0.1051 - acc: 0.9583 - val_loss: 15.9425 - val_acc: 0.0000e+00\n",
      "Epoch 325/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.1255 - acc: 0.9821 - val_loss: 15.9395 - val_acc: 0.0000e+00\n",
      "Epoch 326/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.1186 - acc: 0.9464 - val_loss: 15.9279 - val_acc: 0.0000e+00\n",
      "Epoch 327/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.1478 - acc: 0.9464 - val_loss: 15.9121 - val_acc: 0.0000e+00\n",
      "Epoch 328/1500\n",
      "168/168 [==============================] - 0s 813us/step - loss: 0.1156 - acc: 0.9762 - val_loss: 15.9005 - val_acc: 0.0000e+00\n",
      "Epoch 329/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.1363 - acc: 0.9702 - val_loss: 15.8955 - val_acc: 0.0000e+00\n",
      "Epoch 330/1500\n",
      "168/168 [==============================] - 0s 817us/step - loss: 0.1523 - acc: 0.9464 - val_loss: 15.9081 - val_acc: 0.0000e+00\n",
      "Epoch 331/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.1495 - acc: 0.9643 - val_loss: 15.9326 - val_acc: 0.0000e+00\n",
      "Epoch 332/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.1218 - acc: 0.9762 - val_loss: 15.9519 - val_acc: 0.0000e+00\n",
      "Epoch 333/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.1060 - acc: 0.9702 - val_loss: 15.9620 - val_acc: 0.0000e+00\n",
      "Epoch 334/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0923 - acc: 0.9821 - val_loss: 15.9710 - val_acc: 0.0000e+00\n",
      "Epoch 335/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.1133 - acc: 0.9762 - val_loss: 15.9883 - val_acc: 0.0000e+00\n",
      "Epoch 336/1500\n",
      "168/168 [==============================] - 0s 852us/step - loss: 0.1193 - acc: 0.9762 - val_loss: 15.9993 - val_acc: 0.0000e+00\n",
      "Epoch 337/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.1080 - acc: 0.9702 - val_loss: 16.0104 - val_acc: 0.0000e+00\n",
      "Epoch 338/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 0.0910 - acc: 0.9821 - val_loss: 16.0119 - val_acc: 0.0000e+00\n",
      "Epoch 339/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.1450 - acc: 0.9643 - val_loss: 16.0052 - val_acc: 0.0000e+00\n",
      "Epoch 340/1500\n",
      "168/168 [==============================] - 0s 816us/step - loss: 0.1085 - acc: 0.9702 - val_loss: 15.9975 - val_acc: 0.0000e+00\n",
      "Epoch 341/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.1786 - acc: 0.9524 - val_loss: 15.9820 - val_acc: 0.0000e+00\n",
      "Epoch 342/1500\n",
      "168/168 [==============================] - 0s 855us/step - loss: 0.1522 - acc: 0.9464 - val_loss: 15.9582 - val_acc: 0.0000e+00\n",
      "Epoch 343/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.1520 - acc: 0.9286 - val_loss: 15.9252 - val_acc: 0.0000e+00\n",
      "Epoch 344/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.1182 - acc: 0.9821 - val_loss: 15.9129 - val_acc: 0.0000e+00\n",
      "Epoch 345/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.1355 - acc: 0.9583 - val_loss: 15.9172 - val_acc: 0.0000e+00\n",
      "Epoch 346/1500\n",
      "168/168 [==============================] - 0s 852us/step - loss: 0.1204 - acc: 0.9762 - val_loss: 15.9370 - val_acc: 0.0000e+00\n",
      "Epoch 347/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.1163 - acc: 0.9702 - val_loss: 15.9589 - val_acc: 0.0000e+00\n",
      "Epoch 348/1500\n",
      "168/168 [==============================] - 0s 816us/step - loss: 0.1400 - acc: 0.9464 - val_loss: 15.9730 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.1200 - acc: 0.9643 - val_loss: 15.9847 - val_acc: 0.0000e+00\n",
      "Epoch 350/1500\n",
      "168/168 [==============================] - 0s 820us/step - loss: 0.1402 - acc: 0.9643 - val_loss: 15.9929 - val_acc: 0.0000e+00\n",
      "Epoch 351/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.1222 - acc: 0.9583 - val_loss: 15.9967 - val_acc: 0.0000e+00\n",
      "Epoch 352/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.1086 - acc: 0.9702 - val_loss: 16.0022 - val_acc: 0.0000e+00\n",
      "Epoch 353/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.1663 - acc: 0.9286 - val_loss: 15.9973 - val_acc: 0.0000e+00\n",
      "Epoch 354/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.1399 - acc: 0.9464 - val_loss: 15.9827 - val_acc: 0.0000e+00\n",
      "Epoch 355/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.1129 - acc: 0.9583 - val_loss: 15.9624 - val_acc: 0.0000e+00\n",
      "Epoch 356/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.1608 - acc: 0.9702 - val_loss: 15.9462 - val_acc: 0.0000e+00\n",
      "Epoch 357/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.1299 - acc: 0.9643 - val_loss: 15.9404 - val_acc: 0.0000e+00\n",
      "Epoch 358/1500\n",
      "168/168 [==============================] - 0s 808us/step - loss: 0.1083 - acc: 0.9702 - val_loss: 15.9522 - val_acc: 0.0000e+00\n",
      "Epoch 359/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.1004 - acc: 0.9702 - val_loss: 15.9717 - val_acc: 0.0000e+00\n",
      "Epoch 360/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 0.0942 - acc: 0.9762 - val_loss: 15.9920 - val_acc: 0.0000e+00\n",
      "Epoch 361/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0936 - acc: 0.9821 - val_loss: 16.0017 - val_acc: 0.0000e+00\n",
      "Epoch 362/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0965 - acc: 0.9702 - val_loss: 16.0030 - val_acc: 0.0000e+00\n",
      "Epoch 363/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.1067 - acc: 0.9702 - val_loss: 15.9975 - val_acc: 0.0000e+00\n",
      "Epoch 364/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.1721 - acc: 0.9524 - val_loss: 15.9905 - val_acc: 0.0000e+00\n",
      "Epoch 365/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.1329 - acc: 0.9583 - val_loss: 15.9784 - val_acc: 0.0000e+00\n",
      "Epoch 366/1500\n",
      "168/168 [==============================] - 0s 864us/step - loss: 0.1294 - acc: 0.9643 - val_loss: 15.9665 - val_acc: 0.0000e+00\n",
      "Epoch 367/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.1249 - acc: 0.9702 - val_loss: 15.9575 - val_acc: 0.0000e+00\n",
      "Epoch 368/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.1200 - acc: 0.9762 - val_loss: 15.9566 - val_acc: 0.0000e+00\n",
      "Epoch 369/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.0761 - acc: 0.9762 - val_loss: 15.9626 - val_acc: 0.0000e+00\n",
      "Epoch 370/1500\n",
      "168/168 [==============================] - 0s 867us/step - loss: 0.1108 - acc: 0.9702 - val_loss: 15.9764 - val_acc: 0.0000e+00\n",
      "Epoch 371/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.1106 - acc: 0.9821 - val_loss: 15.9893 - val_acc: 0.0000e+00\n",
      "Epoch 372/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 0.1374 - acc: 0.9583 - val_loss: 16.0015 - val_acc: 0.0000e+00\n",
      "Epoch 373/1500\n",
      "168/168 [==============================] - 0s 885us/step - loss: 0.0807 - acc: 0.9702 - val_loss: 16.0105 - val_acc: 0.0000e+00\n",
      "Epoch 374/1500\n",
      "168/168 [==============================] - 0s 868us/step - loss: 0.0988 - acc: 0.9762 - val_loss: 16.0164 - val_acc: 0.0000e+00\n",
      "Epoch 375/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.1500 - acc: 0.9702 - val_loss: 16.0130 - val_acc: 0.0000e+00\n",
      "Epoch 376/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.1071 - acc: 0.9643 - val_loss: 16.0104 - val_acc: 0.0000e+00\n",
      "Epoch 377/1500\n",
      "168/168 [==============================] - 0s 855us/step - loss: 0.1133 - acc: 0.9643 - val_loss: 16.0095 - val_acc: 0.0000e+00\n",
      "Epoch 378/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.2125 - acc: 0.9583 - val_loss: 16.0080 - val_acc: 0.0000e+00\n",
      "Epoch 379/1500\n",
      "168/168 [==============================] - 0s 871us/step - loss: 0.1155 - acc: 0.9762 - val_loss: 16.0025 - val_acc: 0.0000e+00\n",
      "Epoch 380/1500\n",
      "168/168 [==============================] - 0s 852us/step - loss: 0.1016 - acc: 0.9702 - val_loss: 16.0025 - val_acc: 0.0000e+00\n",
      "Epoch 381/1500\n",
      "168/168 [==============================] - 0s 868us/step - loss: 0.1260 - acc: 0.9583 - val_loss: 16.0083 - val_acc: 0.0000e+00\n",
      "Epoch 382/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.1059 - acc: 0.9762 - val_loss: 16.0119 - val_acc: 0.0000e+00\n",
      "Epoch 383/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0940 - acc: 0.9881 - val_loss: 16.0215 - val_acc: 0.0000e+00\n",
      "Epoch 384/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.1077 - acc: 0.9762 - val_loss: 16.0259 - val_acc: 0.0000e+00\n",
      "Epoch 385/1500\n",
      "168/168 [==============================] - 0s 803us/step - loss: 0.1079 - acc: 0.9762 - val_loss: 16.0310 - val_acc: 0.0000e+00\n",
      "Epoch 386/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.1025 - acc: 0.9643 - val_loss: 16.0318 - val_acc: 0.0000e+00\n",
      "Epoch 387/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0852 - acc: 0.9702 - val_loss: 16.0281 - val_acc: 0.0000e+00\n",
      "Epoch 388/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0728 - acc: 0.9821 - val_loss: 16.0229 - val_acc: 0.0000e+00\n",
      "Epoch 389/1500\n",
      "168/168 [==============================] - 0s 868us/step - loss: 0.0761 - acc: 0.9821 - val_loss: 16.0228 - val_acc: 0.0000e+00\n",
      "Epoch 390/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.2091 - acc: 0.9583 - val_loss: 16.0164 - val_acc: 0.0000e+00\n",
      "Epoch 391/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.1242 - acc: 0.9762 - val_loss: 16.0151 - val_acc: 0.0000e+00\n",
      "Epoch 392/1500\n",
      "168/168 [==============================] - 0s 864us/step - loss: 0.1277 - acc: 0.9583 - val_loss: 16.0154 - val_acc: 0.0000e+00\n",
      "Epoch 393/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.1604 - acc: 0.9524 - val_loss: 16.0238 - val_acc: 0.0000e+00\n",
      "Epoch 394/1500\n",
      "168/168 [==============================] - 0s 864us/step - loss: 0.0753 - acc: 0.9881 - val_loss: 16.0381 - val_acc: 0.0000e+00\n",
      "Epoch 395/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.0820 - acc: 0.9881 - val_loss: 16.0490 - val_acc: 0.0000e+00\n",
      "Epoch 396/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.0817 - acc: 0.9702 - val_loss: 16.0551 - val_acc: 0.0000e+00\n",
      "Epoch 397/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.1010 - acc: 0.9762 - val_loss: 16.0566 - val_acc: 0.0000e+00\n",
      "Epoch 398/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0834 - acc: 0.9821 - val_loss: 16.0544 - val_acc: 0.0000e+00\n",
      "Epoch 399/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.1097 - acc: 0.9405 - val_loss: 16.0442 - val_acc: 0.0000e+00\n",
      "Epoch 400/1500\n",
      "168/168 [==============================] - 0s 869us/step - loss: 0.0974 - acc: 0.9702 - val_loss: 16.0380 - val_acc: 0.0000e+00\n",
      "Epoch 401/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.1106 - acc: 0.9583 - val_loss: 16.0342 - val_acc: 0.0000e+00\n",
      "Epoch 402/1500\n",
      "168/168 [==============================] - 0s 869us/step - loss: 0.1803 - acc: 0.9464 - val_loss: 16.0297 - val_acc: 0.0000e+00\n",
      "Epoch 403/1500\n",
      "168/168 [==============================] - 0s 865us/step - loss: 0.0970 - acc: 0.9762 - val_loss: 16.0303 - val_acc: 0.0000e+00\n",
      "Epoch 404/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.1089 - acc: 0.9583 - val_loss: 16.0324 - val_acc: 0.0000e+00\n",
      "Epoch 405/1500\n",
      "168/168 [==============================] - 0s 856us/step - loss: 0.1033 - acc: 0.9762 - val_loss: 16.0305 - val_acc: 0.0000e+00\n",
      "Epoch 406/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0506 - acc: 0.9940 - val_loss: 16.0308 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0775 - acc: 0.9702 - val_loss: 16.0279 - val_acc: 0.0000e+00\n",
      "Epoch 408/1500\n",
      "168/168 [==============================] - 0s 857us/step - loss: 0.0848 - acc: 0.9762 - val_loss: 16.0244 - val_acc: 0.0000e+00\n",
      "Epoch 409/1500\n",
      "168/168 [==============================] - 0s 853us/step - loss: 0.0854 - acc: 0.9821 - val_loss: 16.0210 - val_acc: 0.0000e+00\n",
      "Epoch 410/1500\n",
      "168/168 [==============================] - 0s 798us/step - loss: 0.0604 - acc: 0.9940 - val_loss: 16.0246 - val_acc: 0.0000e+00\n",
      "Epoch 411/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0858 - acc: 0.9821 - val_loss: 16.0295 - val_acc: 0.0000e+00\n",
      "Epoch 412/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.1293 - acc: 0.9583 - val_loss: 16.0374 - val_acc: 0.0000e+00\n",
      "Epoch 413/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0972 - acc: 0.9762 - val_loss: 16.0409 - val_acc: 0.0000e+00\n",
      "Epoch 414/1500\n",
      "168/168 [==============================] - 0s 801us/step - loss: 0.1073 - acc: 0.9762 - val_loss: 16.0414 - val_acc: 0.0000e+00\n",
      "Epoch 415/1500\n",
      "168/168 [==============================] - 0s 861us/step - loss: 0.0832 - acc: 0.9702 - val_loss: 16.0389 - val_acc: 0.0000e+00\n",
      "Epoch 416/1500\n",
      "168/168 [==============================] - 0s 807us/step - loss: 0.1415 - acc: 0.9643 - val_loss: 16.0401 - val_acc: 0.0000e+00\n",
      "Epoch 417/1500\n",
      "168/168 [==============================] - 0s 893us/step - loss: 0.0872 - acc: 0.9762 - val_loss: 16.0424 - val_acc: 0.0000e+00\n",
      "Epoch 418/1500\n",
      "168/168 [==============================] - 0s 864us/step - loss: 0.0771 - acc: 0.9762 - val_loss: 16.0492 - val_acc: 0.0000e+00\n",
      "Epoch 419/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.1533 - acc: 0.9524 - val_loss: 16.0544 - val_acc: 0.0000e+00\n",
      "Epoch 420/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.0589 - acc: 0.9881 - val_loss: 16.0557 - val_acc: 0.0000e+00\n",
      "Epoch 421/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.0938 - acc: 0.9643 - val_loss: 16.0551 - val_acc: 0.0000e+00\n",
      "Epoch 422/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.1170 - acc: 0.9702 - val_loss: 16.0528 - val_acc: 0.0000e+00\n",
      "Epoch 423/1500\n",
      "168/168 [==============================] - 0s 874us/step - loss: 0.0850 - acc: 0.9762 - val_loss: 16.0518 - val_acc: 0.0000e+00\n",
      "Epoch 424/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.1916 - acc: 0.9524 - val_loss: 16.0526 - val_acc: 0.0000e+00\n",
      "Epoch 425/1500\n",
      "168/168 [==============================] - 0s 856us/step - loss: 0.1017 - acc: 0.9881 - val_loss: 16.0501 - val_acc: 0.0000e+00\n",
      "Epoch 426/1500\n",
      "168/168 [==============================] - 0s 861us/step - loss: 0.0833 - acc: 0.9762 - val_loss: 16.0487 - val_acc: 0.0000e+00\n",
      "Epoch 427/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.1160 - acc: 0.9583 - val_loss: 16.0547 - val_acc: 0.0000e+00\n",
      "Epoch 428/1500\n",
      "168/168 [==============================] - 0s 885us/step - loss: 0.0441 - acc: 0.9940 - val_loss: 16.0615 - val_acc: 0.0000e+00\n",
      "Epoch 429/1500\n",
      "168/168 [==============================] - 0s 875us/step - loss: 0.0582 - acc: 0.9940 - val_loss: 16.0693 - val_acc: 0.0000e+00\n",
      "Epoch 430/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.1031 - acc: 0.9702 - val_loss: 16.0745 - val_acc: 0.0000e+00\n",
      "Epoch 431/1500\n",
      "168/168 [==============================] - 0s 857us/step - loss: 0.0932 - acc: 0.9821 - val_loss: 16.0760 - val_acc: 0.0000e+00\n",
      "Epoch 432/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0719 - acc: 0.9821 - val_loss: 16.0746 - val_acc: 0.0000e+00\n",
      "Epoch 433/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.0946 - acc: 0.9643 - val_loss: 16.0707 - val_acc: 0.0000e+00\n",
      "Epoch 434/1500\n",
      "168/168 [==============================] - 0s 865us/step - loss: 0.0723 - acc: 0.9881 - val_loss: 16.0609 - val_acc: 0.0000e+00\n",
      "Epoch 435/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.1553 - acc: 0.9821 - val_loss: 16.0505 - val_acc: 0.0000e+00\n",
      "Epoch 436/1500\n",
      "168/168 [==============================] - 0s 861us/step - loss: 0.0783 - acc: 0.9881 - val_loss: 16.0494 - val_acc: 0.0000e+00\n",
      "Epoch 437/1500\n",
      "168/168 [==============================] - 0s 862us/step - loss: 0.0624 - acc: 0.9881 - val_loss: 16.0570 - val_acc: 0.0000e+00\n",
      "Epoch 438/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0897 - acc: 0.9643 - val_loss: 16.0678 - val_acc: 0.0000e+00\n",
      "Epoch 439/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.1771 - acc: 0.9702 - val_loss: 16.0723 - val_acc: 0.0000e+00\n",
      "Epoch 440/1500\n",
      "168/168 [==============================] - 0s 859us/step - loss: 0.0565 - acc: 0.9881 - val_loss: 16.0779 - val_acc: 0.0000e+00\n",
      "Epoch 441/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0864 - acc: 0.9821 - val_loss: 16.0841 - val_acc: 0.0000e+00\n",
      "Epoch 442/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.0603 - acc: 0.9940 - val_loss: 16.0887 - val_acc: 0.0000e+00\n",
      "Epoch 443/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.0530 - acc: 0.9940 - val_loss: 16.0906 - val_acc: 0.0000e+00\n",
      "Epoch 444/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 0.1022 - acc: 0.9643 - val_loss: 16.0899 - val_acc: 0.0000e+00\n",
      "Epoch 445/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 0.1185 - acc: 0.9643 - val_loss: 16.0878 - val_acc: 0.0000e+00\n",
      "Epoch 446/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0535 - acc: 0.9881 - val_loss: 16.0874 - val_acc: 0.0000e+00\n",
      "Epoch 447/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 0.0563 - acc: 0.9881 - val_loss: 16.0871 - val_acc: 0.0000e+00\n",
      "Epoch 448/1500\n",
      "168/168 [==============================] - 0s 879us/step - loss: 0.0506 - acc: 0.9881 - val_loss: 16.0849 - val_acc: 0.0000e+00\n",
      "Epoch 449/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.0850 - acc: 0.9821 - val_loss: 16.0840 - val_acc: 0.0000e+00\n",
      "Epoch 450/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0731 - acc: 0.9881 - val_loss: 16.0840 - val_acc: 0.0000e+00\n",
      "Epoch 451/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 0.0958 - acc: 0.9762 - val_loss: 16.0832 - val_acc: 0.0000e+00\n",
      "Epoch 452/1500\n",
      "168/168 [==============================] - 0s 856us/step - loss: 0.0801 - acc: 0.9821 - val_loss: 16.0858 - val_acc: 0.0000e+00\n",
      "Epoch 453/1500\n",
      "168/168 [==============================] - 0s 865us/step - loss: 0.0797 - acc: 0.9821 - val_loss: 16.0877 - val_acc: 0.0000e+00\n",
      "Epoch 454/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0518 - acc: 0.9940 - val_loss: 16.0900 - val_acc: 0.0000e+00\n",
      "Epoch 455/1500\n",
      "168/168 [==============================] - 0s 865us/step - loss: 0.1066 - acc: 0.9762 - val_loss: 16.0917 - val_acc: 0.0000e+00\n",
      "Epoch 456/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.2196 - acc: 0.9464 - val_loss: 16.0917 - val_acc: 0.0000e+00\n",
      "Epoch 457/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0654 - acc: 0.9762 - val_loss: 16.0927 - val_acc: 0.0000e+00\n",
      "Epoch 458/1500\n",
      "168/168 [==============================] - 0s 853us/step - loss: 0.0657 - acc: 0.9762 - val_loss: 16.0936 - val_acc: 0.0000e+00\n",
      "Epoch 459/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0511 - acc: 0.9940 - val_loss: 16.0952 - val_acc: 0.0000e+00\n",
      "Epoch 460/1500\n",
      "168/168 [==============================] - 0s 870us/step - loss: 0.0424 - acc: 1.0000 - val_loss: 16.0969 - val_acc: 0.0000e+00\n",
      "Epoch 461/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.0875 - acc: 0.9821 - val_loss: 16.0963 - val_acc: 0.0000e+00\n",
      "Epoch 462/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.0696 - acc: 0.9762 - val_loss: 16.0934 - val_acc: 0.0000e+00\n",
      "Epoch 463/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0618 - acc: 0.9881 - val_loss: 16.0916 - val_acc: 0.0000e+00\n",
      "Epoch 464/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0751 - acc: 0.9821 - val_loss: 16.0904 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/1500\n",
      "168/168 [==============================] - 0s 862us/step - loss: 0.0519 - acc: 0.9940 - val_loss: 16.0876 - val_acc: 0.0000e+00\n",
      "Epoch 466/1500\n",
      "168/168 [==============================] - 0s 856us/step - loss: 0.0973 - acc: 0.9702 - val_loss: 16.0859 - val_acc: 0.0000e+00\n",
      "Epoch 467/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0400 - acc: 0.9881 - val_loss: 16.0864 - val_acc: 0.0000e+00\n",
      "Epoch 468/1500\n",
      "168/168 [==============================] - 0s 860us/step - loss: 0.0823 - acc: 0.9762 - val_loss: 16.0897 - val_acc: 0.0000e+00\n",
      "Epoch 469/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.0582 - acc: 0.9881 - val_loss: 16.0925 - val_acc: 0.0000e+00\n",
      "Epoch 470/1500\n",
      "168/168 [==============================] - 0s 855us/step - loss: 0.0447 - acc: 0.9881 - val_loss: 16.0950 - val_acc: 0.0000e+00\n",
      "Epoch 471/1500\n",
      "168/168 [==============================] - 0s 799us/step - loss: 0.0595 - acc: 0.9821 - val_loss: 16.0970 - val_acc: 0.0000e+00\n",
      "Epoch 472/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0434 - acc: 0.9940 - val_loss: 16.1002 - val_acc: 0.0000e+00\n",
      "Epoch 473/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0994 - acc: 0.9762 - val_loss: 16.1021 - val_acc: 0.0000e+00\n",
      "Epoch 474/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.1188 - acc: 0.9643 - val_loss: 16.1022 - val_acc: 0.0000e+00\n",
      "Epoch 475/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0629 - acc: 0.9762 - val_loss: 16.1009 - val_acc: 0.0000e+00\n",
      "Epoch 476/1500\n",
      "168/168 [==============================] - 0s 815us/step - loss: 0.1216 - acc: 0.9881 - val_loss: 16.0989 - val_acc: 0.0000e+00\n",
      "Epoch 477/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.2103 - acc: 0.9583 - val_loss: 16.0940 - val_acc: 0.0000e+00\n",
      "Epoch 478/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0383 - acc: 0.9940 - val_loss: 16.0900 - val_acc: 0.0000e+00\n",
      "Epoch 479/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0734 - acc: 0.9762 - val_loss: 16.0858 - val_acc: 0.0000e+00\n",
      "Epoch 480/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0647 - acc: 0.9881 - val_loss: 16.0889 - val_acc: 0.0000e+00\n",
      "Epoch 481/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0661 - acc: 0.9881 - val_loss: 16.0923 - val_acc: 0.0000e+00\n",
      "Epoch 482/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.0526 - acc: 0.9881 - val_loss: 16.0956 - val_acc: 0.0000e+00\n",
      "Epoch 483/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0405 - acc: 1.0000 - val_loss: 16.1006 - val_acc: 0.0000e+00\n",
      "Epoch 484/1500\n",
      "168/168 [==============================] - 0s 817us/step - loss: 0.0622 - acc: 0.9762 - val_loss: 16.1060 - val_acc: 0.0000e+00\n",
      "Epoch 485/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.0370 - acc: 0.9940 - val_loss: 16.1105 - val_acc: 0.0000e+00\n",
      "Epoch 486/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0373 - acc: 0.9940 - val_loss: 16.1122 - val_acc: 0.0000e+00\n",
      "Epoch 487/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0341 - acc: 1.0000 - val_loss: 16.1140 - val_acc: 0.0000e+00\n",
      "Epoch 488/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0720 - acc: 0.9762 - val_loss: 16.1150 - val_acc: 0.0000e+00\n",
      "Epoch 489/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0576 - acc: 0.9881 - val_loss: 16.1153 - val_acc: 0.0000e+00\n",
      "Epoch 490/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0660 - acc: 0.9821 - val_loss: 16.1150 - val_acc: 0.0000e+00\n",
      "Epoch 491/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0497 - acc: 0.9821 - val_loss: 16.1145 - val_acc: 0.0000e+00\n",
      "Epoch 492/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0829 - acc: 0.9583 - val_loss: 16.1124 - val_acc: 0.0000e+00\n",
      "Epoch 493/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.1291 - acc: 0.9643 - val_loss: 16.1095 - val_acc: 0.0000e+00\n",
      "Epoch 494/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0547 - acc: 0.9940 - val_loss: 16.1060 - val_acc: 0.0000e+00\n",
      "Epoch 495/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.0723 - acc: 0.9762 - val_loss: 16.1049 - val_acc: 0.0000e+00\n",
      "Epoch 496/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0563 - acc: 0.9762 - val_loss: 16.1048 - val_acc: 0.0000e+00\n",
      "Epoch 497/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0816 - acc: 0.9762 - val_loss: 16.1040 - val_acc: 0.0000e+00\n",
      "Epoch 498/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.1242 - acc: 0.9881 - val_loss: 16.1038 - val_acc: 0.0000e+00\n",
      "Epoch 499/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.1100 - acc: 0.9583 - val_loss: 16.1042 - val_acc: 0.0000e+00\n",
      "Epoch 500/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0717 - acc: 0.9762 - val_loss: 16.1053 - val_acc: 0.0000e+00\n",
      "Epoch 501/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 0.0611 - acc: 0.9762 - val_loss: 16.1080 - val_acc: 0.0000e+00\n",
      "Epoch 502/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0400 - acc: 0.9940 - val_loss: 16.1109 - val_acc: 0.0000e+00\n",
      "Epoch 503/1500\n",
      "168/168 [==============================] - 0s 811us/step - loss: 0.0583 - acc: 0.9940 - val_loss: 16.1125 - val_acc: 0.0000e+00\n",
      "Epoch 504/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0497 - acc: 0.9881 - val_loss: 16.1142 - val_acc: 0.0000e+00\n",
      "Epoch 505/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0894 - acc: 0.9702 - val_loss: 16.1147 - val_acc: 0.0000e+00\n",
      "Epoch 506/1500\n",
      "168/168 [==============================] - 0s 815us/step - loss: 0.0649 - acc: 0.9881 - val_loss: 16.1132 - val_acc: 0.0000e+00\n",
      "Epoch 507/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0468 - acc: 0.9821 - val_loss: 16.1115 - val_acc: 0.0000e+00\n",
      "Epoch 508/1500\n",
      "168/168 [==============================] - 0s 806us/step - loss: 0.0323 - acc: 0.9940 - val_loss: 16.1101 - val_acc: 0.0000e+00\n",
      "Epoch 509/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.1154 - acc: 0.9464 - val_loss: 16.1096 - val_acc: 0.0000e+00\n",
      "Epoch 510/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0303 - acc: 1.0000 - val_loss: 16.1095 - val_acc: 0.0000e+00\n",
      "Epoch 511/1500\n",
      "168/168 [==============================] - 0s 820us/step - loss: 0.0436 - acc: 0.9881 - val_loss: 16.1091 - val_acc: 0.0000e+00\n",
      "Epoch 512/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.0477 - acc: 0.9881 - val_loss: 16.1096 - val_acc: 0.0000e+00\n",
      "Epoch 513/1500\n",
      "168/168 [==============================] - 0s 816us/step - loss: 0.0615 - acc: 0.9940 - val_loss: 16.1096 - val_acc: 0.0000e+00\n",
      "Epoch 514/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0447 - acc: 0.9821 - val_loss: 16.1099 - val_acc: 0.0000e+00\n",
      "Epoch 515/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0944 - acc: 0.9464 - val_loss: 16.1113 - val_acc: 0.0000e+00\n",
      "Epoch 516/1500\n",
      "168/168 [==============================] - 0s 854us/step - loss: 0.0471 - acc: 0.9940 - val_loss: 16.1134 - val_acc: 0.0000e+00\n",
      "Epoch 517/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0945 - acc: 0.9643 - val_loss: 16.1146 - val_acc: 0.0000e+00\n",
      "Epoch 518/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.1115 - acc: 0.9524 - val_loss: 16.1147 - val_acc: 0.0000e+00\n",
      "Epoch 519/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.1528 - acc: 0.9821 - val_loss: 16.1130 - val_acc: 0.0000e+00\n",
      "Epoch 520/1500\n",
      "168/168 [==============================] - 0s 854us/step - loss: 0.0769 - acc: 0.9821 - val_loss: 16.1102 - val_acc: 0.0000e+00\n",
      "Epoch 521/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0423 - acc: 0.9940 - val_loss: 16.1069 - val_acc: 0.0000e+00\n",
      "Epoch 522/1500\n",
      "168/168 [==============================] - 0s 816us/step - loss: 0.0551 - acc: 0.9881 - val_loss: 16.1035 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/1500\n",
      "168/168 [==============================] - 0s 800us/step - loss: 0.0734 - acc: 0.9762 - val_loss: 16.1024 - val_acc: 0.0000e+00\n",
      "Epoch 524/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.0610 - acc: 0.9821 - val_loss: 16.1029 - val_acc: 0.0000e+00\n",
      "Epoch 525/1500\n",
      "168/168 [==============================] - 0s 816us/step - loss: 0.0623 - acc: 0.9881 - val_loss: 16.1040 - val_acc: 0.0000e+00\n",
      "Epoch 526/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.0703 - acc: 0.9821 - val_loss: 16.1070 - val_acc: 0.0000e+00\n",
      "Epoch 527/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0636 - acc: 0.9821 - val_loss: 16.1119 - val_acc: 0.0000e+00\n",
      "Epoch 528/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0608 - acc: 0.9821 - val_loss: 16.1168 - val_acc: 0.0000e+00\n",
      "Epoch 529/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0437 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 530/1500\n",
      "168/168 [==============================] - 0s 854us/step - loss: 0.0588 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 531/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0502 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 532/1500\n",
      "168/168 [==============================] - 0s 860us/step - loss: 0.0389 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 533/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.1370 - acc: 0.9583 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 534/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0688 - acc: 0.9702 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 535/1500\n",
      "168/168 [==============================] - 0s 812us/step - loss: 0.0779 - acc: 0.9702 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 536/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0454 - acc: 0.9881 - val_loss: 16.1164 - val_acc: 0.0000e+00\n",
      "Epoch 537/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0645 - acc: 0.9762 - val_loss: 16.1140 - val_acc: 0.0000e+00\n",
      "Epoch 538/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.0584 - acc: 0.9821 - val_loss: 16.1125 - val_acc: 0.0000e+00\n",
      "Epoch 539/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0556 - acc: 0.9821 - val_loss: 16.1130 - val_acc: 0.0000e+00\n",
      "Epoch 540/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0402 - acc: 0.9881 - val_loss: 16.1143 - val_acc: 0.0000e+00\n",
      "Epoch 541/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0439 - acc: 0.9940 - val_loss: 16.1162 - val_acc: 0.0000e+00\n",
      "Epoch 542/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.0372 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 543/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0362 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 544/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0337 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 545/1500\n",
      "168/168 [==============================] - 0s 812us/step - loss: 0.1136 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 546/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0962 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 547/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0902 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 548/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0396 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 549/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0248 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 550/1500\n",
      "168/168 [==============================] - 0s 816us/step - loss: 0.0404 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 551/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.0269 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 552/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.0426 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 553/1500\n",
      "168/168 [==============================] - 0s 817us/step - loss: 0.0584 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 554/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0560 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 555/1500\n",
      "168/168 [==============================] - 0s 811us/step - loss: 0.0455 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 556/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.0337 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 557/1500\n",
      "168/168 [==============================] - 0s 812us/step - loss: 0.0554 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 558/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0627 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 559/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0616 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 560/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0614 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 561/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0417 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 562/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.0391 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 563/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0774 - acc: 0.9702 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 564/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0835 - acc: 0.9702 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 565/1500\n",
      "168/168 [==============================] - 0s 852us/step - loss: 0.0426 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 566/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.0618 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 567/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0960 - acc: 0.9762 - val_loss: 16.1173 - val_acc: 0.0000e+00\n",
      "Epoch 568/1500\n",
      "168/168 [==============================] - 0s 820us/step - loss: 0.0417 - acc: 1.0000 - val_loss: 16.1173 - val_acc: 0.0000e+00\n",
      "Epoch 569/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0843 - acc: 0.9881 - val_loss: 16.1174 - val_acc: 0.0000e+00\n",
      "Epoch 570/1500\n",
      "168/168 [==============================] - 0s 798us/step - loss: 0.0387 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 571/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0798 - acc: 0.9643 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 572/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.0644 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 573/1500\n",
      "168/168 [==============================] - 0s 816us/step - loss: 0.0492 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 574/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.1663 - acc: 0.9762 - val_loss: 16.1178 - val_acc: 0.0000e+00\n",
      "Epoch 575/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.0776 - acc: 0.9702 - val_loss: 16.1143 - val_acc: 0.0000e+00\n",
      "Epoch 576/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0375 - acc: 1.0000 - val_loss: 16.1119 - val_acc: 0.0000e+00\n",
      "Epoch 577/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.0486 - acc: 0.9881 - val_loss: 16.1111 - val_acc: 0.0000e+00\n",
      "Epoch 578/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0229 - acc: 1.0000 - val_loss: 16.1111 - val_acc: 0.0000e+00\n",
      "Epoch 579/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0402 - acc: 0.9881 - val_loss: 16.1116 - val_acc: 0.0000e+00\n",
      "Epoch 580/1500\n",
      "168/168 [==============================] - 0s 807us/step - loss: 0.0344 - acc: 1.0000 - val_loss: 16.1128 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 581/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0522 - acc: 0.9821 - val_loss: 16.1151 - val_acc: 0.0000e+00\n",
      "Epoch 582/1500\n",
      "168/168 [==============================] - 0s 813us/step - loss: 0.0301 - acc: 0.9881 - val_loss: 16.1179 - val_acc: 0.0000e+00\n",
      "Epoch 583/1500\n",
      "168/168 [==============================] - 0s 806us/step - loss: 0.0474 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 584/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0755 - acc: 0.9702 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 585/1500\n",
      "168/168 [==============================] - 0s 812us/step - loss: 0.0298 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 586/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0341 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 587/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0949 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 588/1500\n",
      "168/168 [==============================] - 0s 811us/step - loss: 0.0454 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 589/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 0.0826 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 590/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0694 - acc: 0.9524 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 591/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0541 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 592/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0259 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 593/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 594/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.0632 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 595/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0583 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 596/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0601 - acc: 0.9643 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 597/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0659 - acc: 0.9702 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 598/1500\n",
      "168/168 [==============================] - 0s 814us/step - loss: 0.0484 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 599/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0608 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 600/1500\n",
      "168/168 [==============================] - 0s 809us/step - loss: 0.0271 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 601/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 0.0416 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 602/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0549 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 603/1500\n",
      "168/168 [==============================] - 0s 814us/step - loss: 0.0538 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 604/1500\n",
      "168/168 [==============================] - 0s 861us/step - loss: 0.0449 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 605/1500\n",
      "168/168 [==============================] - 0s 815us/step - loss: 0.0638 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 606/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.0565 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 607/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.0677 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 608/1500\n",
      "168/168 [==============================] - 0s 815us/step - loss: 0.0477 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 609/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0529 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 610/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.0277 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 611/1500\n",
      "168/168 [==============================] - 0s 815us/step - loss: 0.0599 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 612/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0353 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 613/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.0508 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 614/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0597 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 615/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0417 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 616/1500\n",
      "168/168 [==============================] - 0s 814us/step - loss: 0.0277 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 617/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0318 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 618/1500\n",
      "168/168 [==============================] - 0s 813us/step - loss: 0.0759 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 619/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 620/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0548 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 621/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.0357 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 622/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0453 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 623/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0384 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 624/1500\n",
      "168/168 [==============================] - 0s 856us/step - loss: 0.0255 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 625/1500\n",
      "168/168 [==============================] - 0s 811us/step - loss: 0.0427 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 626/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.0309 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 627/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0668 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 628/1500\n",
      "168/168 [==============================] - 0s 814us/step - loss: 0.0507 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 629/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.0375 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 630/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 0.0518 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 631/1500\n",
      "168/168 [==============================] - 0s 815us/step - loss: 0.0332 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 632/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0297 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 633/1500\n",
      "168/168 [==============================] - 0s 815us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 634/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0744 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 635/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0260 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 636/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.0260 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 637/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.1645 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 638/1500\n",
      "168/168 [==============================] - 0s 853us/step - loss: 0.0419 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 639/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0268 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 640/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.0850 - acc: 0.9702 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 641/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0401 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 642/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.1240 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 643/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0540 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 644/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0280 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 645/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0274 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 646/1500\n",
      "168/168 [==============================] - 0s 815us/step - loss: 0.0437 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 647/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 0.1190 - acc: 0.9702 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 648/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0400 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 649/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0231 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 650/1500\n",
      "168/168 [==============================] - 0s 817us/step - loss: 0.0428 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 651/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0403 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 652/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0485 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 653/1500\n",
      "168/168 [==============================] - 0s 809us/step - loss: 0.0293 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 654/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0515 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 655/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0402 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 656/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0256 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 657/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0267 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 658/1500\n",
      "168/168 [==============================] - 0s 859us/step - loss: 0.0331 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 659/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0401 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 660/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0175 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 661/1500\n",
      "168/168 [==============================] - 0s 894us/step - loss: 0.0360 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 662/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0361 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 663/1500\n",
      "168/168 [==============================] - 0s 812us/step - loss: 0.0209 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 664/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.0249 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 665/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0472 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 666/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 667/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 668/1500\n",
      "168/168 [==============================] - 0s 853us/step - loss: 0.0685 - acc: 0.9643 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 669/1500\n",
      "168/168 [==============================] - 0s 816us/step - loss: 0.0303 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 670/1500\n",
      "168/168 [==============================] - 0s 810us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 671/1500\n",
      "168/168 [==============================] - 0s 852us/step - loss: 0.0355 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 672/1500\n",
      "168/168 [==============================] - 0s 806us/step - loss: 0.0777 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 673/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0227 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 674/1500\n",
      "168/168 [==============================] - 0s 854us/step - loss: 0.0836 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 675/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.0292 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 676/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0308 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 677/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0200 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 678/1500\n",
      "168/168 [==============================] - 0s 864us/step - loss: 0.0372 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 679/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0487 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 680/1500\n",
      "168/168 [==============================] - 0s 861us/step - loss: 0.0929 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 681/1500\n",
      "168/168 [==============================] - 0s 868us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 682/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.0187 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 683/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 684/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.0328 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 685/1500\n",
      "168/168 [==============================] - 0s 866us/step - loss: 0.0263 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 686/1500\n",
      "168/168 [==============================] - 0s 855us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 687/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0285 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 688/1500\n",
      "168/168 [==============================] - 0s 866us/step - loss: 0.0577 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 689/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 0.0328 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 690/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0317 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 691/1500\n",
      "168/168 [==============================] - 0s 875us/step - loss: 0.0213 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 692/1500\n",
      "168/168 [==============================] - 0s 877us/step - loss: 0.0255 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 693/1500\n",
      "168/168 [==============================] - 0s 857us/step - loss: 0.0326 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 694/1500\n",
      "168/168 [==============================] - 0s 906us/step - loss: 0.0411 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 695/1500\n",
      "168/168 [==============================] - 0s 852us/step - loss: 0.0463 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 696/1500\n",
      "168/168 [==============================] - 0s 811us/step - loss: 0.0226 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 697/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0304 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 698/1500\n",
      "168/168 [==============================] - 0s 885us/step - loss: 0.0299 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 699/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 0.0287 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 700/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0280 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 701/1500\n",
      "168/168 [==============================] - 0s 861us/step - loss: 0.0254 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 702/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0193 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 703/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0323 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 704/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0798 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 705/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0223 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 706/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.0289 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 707/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0403 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 708/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 709/1500\n",
      "168/168 [==============================] - 0s 813us/step - loss: 0.0186 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 710/1500\n",
      "168/168 [==============================] - 0s 875us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 711/1500\n",
      "168/168 [==============================] - 0s 857us/step - loss: 0.0577 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 712/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0247 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 713/1500\n",
      "168/168 [==============================] - 0s 868us/step - loss: 0.0407 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 714/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0367 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 715/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0913 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 716/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.0390 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 717/1500\n",
      "168/168 [==============================] - 0s 867us/step - loss: 0.0212 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 718/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0222 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 719/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0413 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 720/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.0237 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 721/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0244 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 722/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 723/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.0765 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 724/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0319 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 725/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0331 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 726/1500\n",
      "168/168 [==============================] - 0s 857us/step - loss: 0.0541 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 727/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0421 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 728/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0388 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 729/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 730/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0325 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 731/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 732/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0380 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 733/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.0343 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 734/1500\n",
      "168/168 [==============================] - 0s 864us/step - loss: 0.0331 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 735/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0474 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 736/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 0.0539 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 737/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0188 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 738/1500\n",
      "168/168 [==============================] - 0s 860us/step - loss: 0.0468 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 739/1500\n",
      "168/168 [==============================] - 0s 820us/step - loss: 0.0356 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 740/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0385 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 741/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0651 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 742/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.0369 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 743/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0711 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 744/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0485 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 745/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0411 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 746/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 747/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.0551 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 748/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0389 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 749/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0408 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 750/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 751/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0361 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 752/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0401 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 753/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 754/1500\n",
      "168/168 [==============================] - 0s 817us/step - loss: 0.0368 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 755/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 756/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0412 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 757/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 758/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 759/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0381 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 760/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0416 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 761/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0350 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 762/1500\n",
      "168/168 [==============================] - 0s 852us/step - loss: 0.0186 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 763/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0145 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 764/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0420 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 765/1500\n",
      "168/168 [==============================] - 0s 807us/step - loss: 0.0447 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 766/1500\n",
      "168/168 [==============================] - 0s 855us/step - loss: 0.0207 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 767/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0262 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 768/1500\n",
      "168/168 [==============================] - 0s 817us/step - loss: 0.0799 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 769/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.0631 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 770/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0303 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 771/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 772/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0451 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 773/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.0539 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 774/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0405 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 775/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0608 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 776/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 0.0388 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 777/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0630 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 778/1500\n",
      "168/168 [==============================] - 0s 855us/step - loss: 0.0440 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 779/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0266 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 780/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0496 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 781/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0245 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 782/1500\n",
      "168/168 [==============================] - 0s 896us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 783/1500\n",
      "168/168 [==============================] - 0s 877us/step - loss: 0.0864 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 784/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0623 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 785/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 786/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 787/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.0700 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 788/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0741 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 789/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0305 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 790/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0312 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 791/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0374 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 792/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0712 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 793/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0254 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 794/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0325 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 795/1500\n",
      "168/168 [==============================] - 0s 859us/step - loss: 0.0296 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 796/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0259 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 797/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0253 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 798/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.0277 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 799/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 800/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0406 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 801/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 0.0365 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 802/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0312 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 803/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0241 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 804/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0239 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 805/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.0332 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 806/1500\n",
      "168/168 [==============================] - 0s 866us/step - loss: 0.0335 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 807/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 808/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 809/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0232 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 810/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0261 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 811/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0454 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 812/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0240 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 813/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.0280 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 814/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0346 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 815/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0382 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 816/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0224 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 817/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0206 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 818/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0423 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 819/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0610 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 820/1500\n",
      "168/168 [==============================] - 0s 899us/step - loss: 0.0288 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 821/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0201 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 822/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0370 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 823/1500\n",
      "168/168 [==============================] - 0s 889us/step - loss: 0.0439 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 824/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0320 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 825/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.0209 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 826/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 827/1500\n",
      "168/168 [==============================] - 0s 883us/step - loss: 0.0373 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 828/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 829/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.0517 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 830/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.1017 - acc: 0.9702 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 831/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0564 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 832/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.0299 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 833/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0675 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 834/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 835/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 836/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0389 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 837/1500\n",
      "168/168 [==============================] - 0s 867us/step - loss: 0.0670 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 838/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.0225 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 839/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.0202 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 840/1500\n",
      "168/168 [==============================] - 0s 916us/step - loss: 0.0597 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 841/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0329 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 842/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.0344 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 843/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.0249 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 844/1500\n",
      "168/168 [==============================] - 0s 876us/step - loss: 0.0552 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 845/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0207 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 846/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 847/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.0548 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 848/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 849/1500\n",
      "168/168 [==============================] - 0s 857us/step - loss: 0.0328 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 850/1500\n",
      "168/168 [==============================] - 0s 865us/step - loss: 0.0287 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 851/1500\n",
      "168/168 [==============================] - 0s 860us/step - loss: 0.0292 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 852/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.0765 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 853/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0177 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 854/1500\n",
      "168/168 [==============================] - 0s 817us/step - loss: 0.0350 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 855/1500\n",
      "168/168 [==============================] - 0s 859us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 856/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.0361 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 857/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0214 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 858/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.0138 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 859/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 860/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.0201 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 861/1500\n",
      "168/168 [==============================] - 0s 807us/step - loss: 0.0299 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 862/1500\n",
      "168/168 [==============================] - 0s 872us/step - loss: 0.0460 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 863/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0357 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 864/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0277 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 865/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0559 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 866/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 867/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0833 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 868/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0660 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 869/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0293 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 870/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.0676 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 871/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0267 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 872/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0304 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 873/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0350 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 874/1500\n",
      "168/168 [==============================] - 0s 820us/step - loss: 0.1046 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 875/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0286 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 876/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0201 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 877/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 0.0314 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 878/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0321 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 879/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0219 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 880/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 881/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0368 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 882/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.0187 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 883/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0268 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 884/1500\n",
      "168/168 [==============================] - 0s 867us/step - loss: 0.0384 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 885/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0393 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 886/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 887/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0519 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 888/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.0444 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 889/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 890/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0321 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 891/1500\n",
      "168/168 [==============================] - 0s 862us/step - loss: 0.0263 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 892/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0980 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 893/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0228 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 894/1500\n",
      "168/168 [==============================] - 0s 852us/step - loss: 0.0206 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 895/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 896/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 897/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0589 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 898/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 899/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0130 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 900/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0205 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 901/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0472 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 902/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.1044 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 903/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 904/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0349 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 905/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0281 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 906/1500\n",
      "168/168 [==============================] - 0s 861us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 907/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 908/1500\n",
      "168/168 [==============================] - 0s 863us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 909/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0414 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 910/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 0.0299 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 911/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0334 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 912/1500\n",
      "168/168 [==============================] - 0s 856us/step - loss: 0.0161 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 913/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 914/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 915/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 916/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 917/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.0245 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 918/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.0289 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 919/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0250 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 920/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 921/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0237 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 922/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 923/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0140 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 924/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0318 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 925/1500\n",
      "168/168 [==============================] - 0s 820us/step - loss: 0.0286 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 926/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0200 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 927/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 0.0299 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 928/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0178 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 929/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0173 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 930/1500\n",
      "168/168 [==============================] - 0s 857us/step - loss: 0.0227 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 931/1500\n",
      "168/168 [==============================] - 0s 816us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 932/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0526 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 933/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0219 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 934/1500\n",
      "168/168 [==============================] - 0s 864us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 935/1500\n",
      "168/168 [==============================] - 0s 864us/step - loss: 0.0134 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 936/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 937/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0220 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 938/1500\n",
      "168/168 [==============================] - 0s 814us/step - loss: 0.0257 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 939/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0204 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 940/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 941/1500\n",
      "168/168 [==============================] - 0s 810us/step - loss: 0.0290 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 942/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.0210 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 943/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0226 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 944/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 945/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 946/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0124 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 947/1500\n",
      "168/168 [==============================] - 0s 854us/step - loss: 0.0666 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 948/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0166 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 949/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.0390 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 950/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0368 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 951/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0307 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 952/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.0473 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 953/1500\n",
      "168/168 [==============================] - 0s 816us/step - loss: 0.0212 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 954/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 955/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0359 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 956/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 957/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 0.0224 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 958/1500\n",
      "168/168 [==============================] - 0s 815us/step - loss: 0.0324 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 959/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0330 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 960/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0220 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 961/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0171 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 962/1500\n",
      "168/168 [==============================] - 0s 869us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 963/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 964/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 965/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0314 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 966/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0254 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 967/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0298 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 968/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0377 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 969/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.0266 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 970/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 971/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 972/1500\n",
      "168/168 [==============================] - 0s 861us/step - loss: 0.0306 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 973/1500\n",
      "168/168 [==============================] - 0s 854us/step - loss: 0.0231 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 974/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 975/1500\n",
      "168/168 [==============================] - 0s 868us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 976/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 977/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 978/1500\n",
      "168/168 [==============================] - 0s 862us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 979/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0187 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 980/1500\n",
      "168/168 [==============================] - 0s 816us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 981/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.0155 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 982/1500\n",
      "168/168 [==============================] - 0s 814us/step - loss: 0.0209 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 983/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0271 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 984/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 985/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0182 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 986/1500\n",
      "168/168 [==============================] - 0s 880us/step - loss: 0.0232 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 987/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0188 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 988/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.0860 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 989/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 990/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0364 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 991/1500\n",
      "168/168 [==============================] - 0s 895us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 992/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 993/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 994/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0340 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 995/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.0408 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 996/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 997/1500\n",
      "168/168 [==============================] - 0s 815us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 998/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 999/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.0197 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1000/1500\n",
      "168/168 [==============================] - 0s 852us/step - loss: 0.0249 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1001/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1002/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1003/1500\n",
      "168/168 [==============================] - 0s 890us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1004/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0218 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1005/1500\n",
      "168/168 [==============================] - 0s 872us/step - loss: 0.0170 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1006/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0649 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1007/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.0311 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1008/1500\n",
      "168/168 [==============================] - 0s 852us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1009/1500\n",
      "168/168 [==============================] - 0s 853us/step - loss: 0.0141 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1010/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1011/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.0122 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1012/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1013/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0196 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1014/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0264 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1015/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1016/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0177 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1017/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1018/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1019/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0632 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1020/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1021/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0277 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1022/1500\n",
      "168/168 [==============================] - 0s 868us/step - loss: 0.0331 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1023/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0168 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1024/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0261 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1025/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0166 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1026/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1027/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0659 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1028/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1029/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0557 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1030/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0117 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1031/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0163 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1032/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 0.0325 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1033/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0357 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1034/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.0478 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1035/1500\n",
      "168/168 [==============================] - 0s 816us/step - loss: 0.0272 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1036/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1037/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0267 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1038/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0214 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1039/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.0230 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1040/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.0204 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1041/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0196 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1042/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1043/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1044/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.0408 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1045/1500\n",
      "168/168 [==============================] - 0s 885us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1046/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1047/1500\n",
      "168/168 [==============================] - 0s 820us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1048/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0394 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1049/1500\n",
      "168/168 [==============================] - 0s 816us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1050/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0109 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1051/1500\n",
      "168/168 [==============================] - 0s 852us/step - loss: 0.0202 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1052/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1053/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1054/1500\n",
      "168/168 [==============================] - 0s 854us/step - loss: 0.0532 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1055/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0125 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1056/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0167 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1057/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0304 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1058/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0137 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1059/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1060/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1061/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1062/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1063/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0189 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1064/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1065/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1066/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0219 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1067/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.0185 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1068/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1069/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1070/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0180 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1071/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0352 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1072/1500\n",
      "168/168 [==============================] - 0s 817us/step - loss: 0.0579 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1073/1500\n",
      "168/168 [==============================] - 0s 872us/step - loss: 0.0286 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1074/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.0386 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1075/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1076/1500\n",
      "168/168 [==============================] - 0s 854us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1077/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0168 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1078/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1079/1500\n",
      "168/168 [==============================] - 0s 815us/step - loss: 0.0401 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1080/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0270 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1081/1500\n",
      "168/168 [==============================] - 0s 859us/step - loss: 0.0140 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1082/1500\n",
      "168/168 [==============================] - 0s 797us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1083/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1084/1500\n",
      "168/168 [==============================] - 0s 888us/step - loss: 0.0504 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1085/1500\n",
      "168/168 [==============================] - 0s 813us/step - loss: 0.0247 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1086/1500\n",
      "168/168 [==============================] - 0s 887us/step - loss: 0.0162 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1087/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1088/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0698 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1089/1500\n",
      "168/168 [==============================] - 0s 884us/step - loss: 0.0293 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1090/1500\n",
      "168/168 [==============================] - 0s 868us/step - loss: 0.0245 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1091/1500\n",
      "168/168 [==============================] - 0s 894us/step - loss: 0.0127 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1092/1500\n",
      "168/168 [==============================] - 0s 871us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1093/1500\n",
      "168/168 [==============================] - 0s 860us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1094/1500\n",
      "168/168 [==============================] - 0s 881us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1095/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0384 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1096/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.0582 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1097/1500\n",
      "168/168 [==============================] - 0s 888us/step - loss: 0.0356 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1098/1500\n",
      "168/168 [==============================] - 0s 860us/step - loss: 0.0237 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1099/1500\n",
      "168/168 [==============================] - 0s 880us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1100/1500\n",
      "168/168 [==============================] - 0s 853us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1101/1500\n",
      "168/168 [==============================] - 0s 885us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1102/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0288 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1103/1500\n",
      "168/168 [==============================] - 0s 856us/step - loss: 0.0197 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1104/1500\n",
      "168/168 [==============================] - 0s 859us/step - loss: 0.0218 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1105/1500\n",
      "168/168 [==============================] - 0s 863us/step - loss: 0.0521 - acc: 0.9702 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1106/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0589 - acc: 0.9762 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1107/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1108/1500\n",
      "168/168 [==============================] - 0s 860us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1109/1500\n",
      "168/168 [==============================] - 0s 871us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1110/1500\n",
      "168/168 [==============================] - 0s 860us/step - loss: 0.0236 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1111/1500\n",
      "168/168 [==============================] - 0s 853us/step - loss: 0.1028 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1112/1500\n",
      "168/168 [==============================] - 0s 861us/step - loss: 0.0205 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1113/1500\n",
      "168/168 [==============================] - 0s 870us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1114/1500\n",
      "168/168 [==============================] - 0s 877us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1115/1500\n",
      "168/168 [==============================] - 0s 856us/step - loss: 0.0178 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1116/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1117/1500\n",
      "168/168 [==============================] - 0s 871us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1118/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1119/1500\n",
      "168/168 [==============================] - 0s 877us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1120/1500\n",
      "168/168 [==============================] - 0s 872us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1121/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1122/1500\n",
      "168/168 [==============================] - 0s 885us/step - loss: 0.0337 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1123/1500\n",
      "168/168 [==============================] - 0s 878us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1124/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0119 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1125/1500\n",
      "168/168 [==============================] - 0s 861us/step - loss: 0.0325 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1126/1500\n",
      "168/168 [==============================] - 0s 870us/step - loss: 0.0147 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1127/1500\n",
      "168/168 [==============================] - 0s 865us/step - loss: 0.0139 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1128/1500\n",
      "168/168 [==============================] - 0s 874us/step - loss: 0.0128 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1129/1500\n",
      "168/168 [==============================] - 0s 867us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1130/1500\n",
      "168/168 [==============================] - 0s 857us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1131/1500\n",
      "168/168 [==============================] - 0s 865us/step - loss: 0.0217 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1132/1500\n",
      "168/168 [==============================] - 0s 853us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1133/1500\n",
      "168/168 [==============================] - 0s 857us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1134/1500\n",
      "168/168 [==============================] - 0s 856us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1135/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0165 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1136/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.0139 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1137/1500\n",
      "168/168 [==============================] - 0s 864us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1138/1500\n",
      "168/168 [==============================] - 0s 886us/step - loss: 0.0182 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1139/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1140/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0156 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1141/1500\n",
      "168/168 [==============================] - 0s 863us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1142/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1143/1500\n",
      "168/168 [==============================] - 0s 857us/step - loss: 0.0257 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1144/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1145/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1146/1500\n",
      "168/168 [==============================] - 0s 856us/step - loss: 0.0365 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1147/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1148/1500\n",
      "168/168 [==============================] - 0s 855us/step - loss: 0.0145 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1149/1500\n",
      "168/168 [==============================] - 0s 857us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1150/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.0156 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1151/1500\n",
      "168/168 [==============================] - 0s 866us/step - loss: 0.0164 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1152/1500\n",
      "168/168 [==============================] - 0s 863us/step - loss: 0.0184 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1153/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.0274 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1154/1500\n",
      "168/168 [==============================] - 0s 876us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1155/1500\n",
      "168/168 [==============================] - 0s 856us/step - loss: 0.0214 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1156/1500\n",
      "168/168 [==============================] - 0s 852us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1157/1500\n",
      "168/168 [==============================] - 0s 857us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1158/1500\n",
      "168/168 [==============================] - 0s 854us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1159/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1160/1500\n",
      "168/168 [==============================] - 0s 889us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1161/1500\n",
      "168/168 [==============================] - 0s 897us/step - loss: 0.0134 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1162/1500\n",
      "168/168 [==============================] - 0s 865us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1163/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1164/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1165/1500\n",
      "168/168 [==============================] - 0s 898us/step - loss: 0.0333 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1166/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.0143 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1167/1500\n",
      "168/168 [==============================] - 0s 872us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1168/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0259 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1169/1500\n",
      "168/168 [==============================] - 0s 856us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1170/1500\n",
      "168/168 [==============================] - 0s 853us/step - loss: 0.0150 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1171/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1172/1500\n",
      "168/168 [==============================] - 0s 863us/step - loss: 0.0394 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1173/1500\n",
      "168/168 [==============================] - 0s 867us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1174/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1175/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0250 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1176/1500\n",
      "168/168 [==============================] - 0s 903us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1177/1500\n",
      "168/168 [==============================] - 0s 852us/step - loss: 0.0372 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1178/1500\n",
      "168/168 [==============================] - 0s 873us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1179/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1180/1500\n",
      "168/168 [==============================] - 0s 856us/step - loss: 0.0207 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1181/1500\n",
      "168/168 [==============================] - 0s 856us/step - loss: 0.0132 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1182/1500\n",
      "168/168 [==============================] - 0s 863us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1183/1500\n",
      "168/168 [==============================] - 0s 855us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1184/1500\n",
      "168/168 [==============================] - 0s 907us/step - loss: 0.0133 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1185/1500\n",
      "168/168 [==============================] - 0s 860us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1186/1500\n",
      "168/168 [==============================] - 0s 893us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1187/1500\n",
      "168/168 [==============================] - 0s 873us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1188/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 0.0427 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1189/1500\n",
      "168/168 [==============================] - 0s 862us/step - loss: 0.0259 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1190/1500\n",
      "168/168 [==============================] - 0s 853us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1191/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1192/1500\n",
      "168/168 [==============================] - 0s 894us/step - loss: 0.0134 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1193/1500\n",
      "168/168 [==============================] - 0s 867us/step - loss: 0.0137 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1194/1500\n",
      "168/168 [==============================] - 0s 862us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1195/1500\n",
      "168/168 [==============================] - 0s 852us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1196/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0224 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1197/1500\n",
      "168/168 [==============================] - 0s 865us/step - loss: 0.0216 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1198/1500\n",
      "168/168 [==============================] - 0s 869us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1199/1500\n",
      "168/168 [==============================] - 0s 879us/step - loss: 0.0168 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1200/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0422 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1201/1500\n",
      "168/168 [==============================] - 0s 874us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1202/1500\n",
      "168/168 [==============================] - 0s 864us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1203/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1204/1500\n",
      "168/168 [==============================] - 0s 879us/step - loss: 0.0183 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1205/1500\n",
      "168/168 [==============================] - 0s 879us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1206/1500\n",
      "168/168 [==============================] - 0s 863us/step - loss: 0.0170 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1207/1500\n",
      "168/168 [==============================] - 0s 853us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1208/1500\n",
      "168/168 [==============================] - 0s 855us/step - loss: 0.0154 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1209/1500\n",
      "168/168 [==============================] - 0s 864us/step - loss: 0.0158 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1210/1500\n",
      "168/168 [==============================] - 0s 852us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1211/1500\n",
      "168/168 [==============================] - 0s 867us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1212/1500\n",
      "168/168 [==============================] - 0s 853us/step - loss: 0.0207 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1213/1500\n",
      "168/168 [==============================] - 0s 854us/step - loss: 0.0189 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1214/1500\n",
      "168/168 [==============================] - 0s 865us/step - loss: 0.0161 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1215/1500\n",
      "168/168 [==============================] - 0s 855us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1216/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1217/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.0121 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1218/1500\n",
      "168/168 [==============================] - 0s 863us/step - loss: 0.0358 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1219/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0224 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1220/1500\n",
      "168/168 [==============================] - 0s 868us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1221/1500\n",
      "168/168 [==============================] - 0s 888us/step - loss: 0.0148 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1222/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0208 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1223/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0086 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1224/1500\n",
      "168/168 [==============================] - 0s 862us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1225/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1226/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.0266 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1227/1500\n",
      "168/168 [==============================] - 0s 872us/step - loss: 0.0428 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1228/1500\n",
      "168/168 [==============================] - 0s 869us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1229/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0104 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1230/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1231/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0143 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1232/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1233/1500\n",
      "168/168 [==============================] - 0s 855us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1234/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0701 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1235/1500\n",
      "168/168 [==============================] - 0s 857us/step - loss: 0.0128 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1236/1500\n",
      "168/168 [==============================] - 0s 872us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1237/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0180 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1238/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0250 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1239/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0291 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1240/1500\n",
      "168/168 [==============================] - 0s 861us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1241/1500\n",
      "168/168 [==============================] - 0s 854us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1242/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0329 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1243/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1244/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1245/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0159 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1246/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1247/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1248/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1249/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1250/1500\n",
      "168/168 [==============================] - 0s 855us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1251/1500\n",
      "168/168 [==============================] - 0s 860us/step - loss: 0.0218 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1252/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0211 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1253/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.0279 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1254/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.0202 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1255/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1256/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.0211 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1257/1500\n",
      "168/168 [==============================] - 0s 863us/step - loss: 0.0286 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1258/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0191 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1259/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1260/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0182 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1261/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1262/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1263/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1264/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1265/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1266/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0205 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1267/1500\n",
      "168/168 [==============================] - 0s 866us/step - loss: 0.0149 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1268/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0411 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1269/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0098 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1270/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0231 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1271/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0122 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1272/1500\n",
      "168/168 [==============================] - 0s 820us/step - loss: 0.0324 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1273/1500\n",
      "168/168 [==============================] - 0s 868us/step - loss: 0.0096 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1274/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1275/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0136 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1276/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0087 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1277/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1278/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1279/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 0.0203 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1280/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1281/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1282/1500\n",
      "168/168 [==============================] - 0s 854us/step - loss: 0.0595 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1283/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1284/1500\n",
      "168/168 [==============================] - 0s 815us/step - loss: 0.0149 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1285/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1286/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1287/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1288/1500\n",
      "168/168 [==============================] - 0s 820us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1289/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0299 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1290/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.0152 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1291/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0348 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1292/1500\n",
      "168/168 [==============================] - 0s 855us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1293/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1294/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1295/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.0123 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1296/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.0137 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1297/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1298/1500\n",
      "168/168 [==============================] - 0s 820us/step - loss: 0.0128 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1299/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0252 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1300/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.0226 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1301/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0162 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1302/1500\n",
      "168/168 [==============================] - 0s 856us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1303/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1304/1500\n",
      "168/168 [==============================] - 0s 854us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1305/1500\n",
      "168/168 [==============================] - 0s 809us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1306/1500\n",
      "168/168 [==============================] - 0s 817us/step - loss: 0.0156 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1307/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1308/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0235 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1309/1500\n",
      "168/168 [==============================] - 0s 825us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1310/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0362 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1311/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1312/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1313/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1314/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1315/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0131 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1316/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0136 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1317/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.0368 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1318/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1319/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0216 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1320/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1321/1500\n",
      "168/168 [==============================] - 0s 914us/step - loss: 0.0125 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1322/1500\n",
      "168/168 [==============================] - 0s 809us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1323/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0210 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1324/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0207 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1325/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0134 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1326/1500\n",
      "168/168 [==============================] - 0s 858us/step - loss: 0.0275 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1327/1500\n",
      "168/168 [==============================] - 0s 813us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1328/1500\n",
      "168/168 [==============================] - 0s 863us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1329/1500\n",
      "168/168 [==============================] - 0s 856us/step - loss: 0.0156 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1330/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1331/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.0204 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1332/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.0094 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1333/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0238 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1334/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.0121 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1335/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1336/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1337/1500\n",
      "168/168 [==============================] - 0s 857us/step - loss: 0.0169 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1338/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0132 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1339/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0300 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1340/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1341/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1342/1500\n",
      "168/168 [==============================] - 0s 867us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1343/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1344/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1345/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1346/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1347/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0207 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1348/1500\n",
      "168/168 [==============================] - 0s 818us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1349/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0133 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1350/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0283 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1351/1500\n",
      "168/168 [==============================] - 0s 814us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1352/1500\n",
      "168/168 [==============================] - 0s 811us/step - loss: 0.0104 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1353/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0503 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1354/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0179 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1355/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1356/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0280 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1357/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1358/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1359/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1360/1500\n",
      "168/168 [==============================] - 0s 840us/step - loss: 0.0211 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1361/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0134 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1362/1500\n",
      "168/168 [==============================] - 0s 813us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1363/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0216 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1364/1500\n",
      "168/168 [==============================] - 0s 817us/step - loss: 0.0163 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1365/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.0283 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1366/1500\n",
      "168/168 [==============================] - 0s 805us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1367/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0105 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1368/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.0235 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1369/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0203 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1370/1500\n",
      "168/168 [==============================] - 0s 871us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1371/1500\n",
      "168/168 [==============================] - 0s 821us/step - loss: 0.0533 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1372/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0089 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1373/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0282 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1374/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0163 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1375/1500\n",
      "168/168 [==============================] - 0s 815us/step - loss: 0.0118 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1376/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0167 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1377/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0292 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1378/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1379/1500\n",
      "168/168 [==============================] - 0s 906us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1380/1500\n",
      "168/168 [==============================] - 0s 868us/step - loss: 0.0217 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1381/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1382/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0107 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1383/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0200 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1384/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1385/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0168 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1386/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0155 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1387/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0277 - acc: 0.9821 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1388/1500\n",
      "168/168 [==============================] - 0s 875us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1389/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1390/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1391/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1392/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1393/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0218 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1394/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.0417 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1395/1500\n",
      "168/168 [==============================] - 0s 815us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1396/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1397/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1398/1500\n",
      "168/168 [==============================] - 0s 830us/step - loss: 0.0130 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1399/1500\n",
      "168/168 [==============================] - 0s 822us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1400/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0154 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1401/1500\n",
      "168/168 [==============================] - 0s 852us/step - loss: 0.0210 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1402/1500\n",
      "168/168 [==============================] - 0s 807us/step - loss: 0.0144 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1403/1500\n",
      "168/168 [==============================] - 0s 853us/step - loss: 0.0529 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1404/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1405/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1406/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1407/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1408/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 0.0171 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1409/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1410/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1411/1500\n",
      "168/168 [==============================] - 0s 846us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1412/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1413/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1414/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1415/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0125 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1416/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0192 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1417/1500\n",
      "168/168 [==============================] - 0s 878us/step - loss: 0.0206 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1418/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0183 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1419/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0091 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1420/1500\n",
      "168/168 [==============================] - 0s 861us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1421/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0086 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1422/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0228 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1423/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1424/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0134 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1425/1500\n",
      "168/168 [==============================] - 0s 827us/step - loss: 0.0104 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1426/1500\n",
      "168/168 [==============================] - 0s 837us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1427/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1428/1500\n",
      "168/168 [==============================] - 0s 873us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1429/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0120 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1430/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1431/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1432/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1433/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.0178 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1434/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.0101 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1435/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1436/1500\n",
      "168/168 [==============================] - 0s 816us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1437/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1438/1500\n",
      "168/168 [==============================] - 0s 811us/step - loss: 0.0099 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1439/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1440/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1441/1500\n",
      "168/168 [==============================] - 0s 803us/step - loss: 0.0257 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1442/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.0263 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1443/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1444/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1445/1500\n",
      "168/168 [==============================] - 0s 851us/step - loss: 0.0127 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1446/1500\n",
      "168/168 [==============================] - 0s 888us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1447/1500\n",
      "168/168 [==============================] - 0s 867us/step - loss: 0.0120 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1448/1500\n",
      "168/168 [==============================] - 0s 879us/step - loss: 0.0164 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1449/1500\n",
      "168/168 [==============================] - 0s 843us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1450/1500\n",
      "168/168 [==============================] - 0s 849us/step - loss: 0.0153 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1451/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1452/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1453/1500\n",
      "168/168 [==============================] - 0s 915us/step - loss: 0.0307 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1454/1500\n",
      "168/168 [==============================] - 0s 857us/step - loss: 0.0190 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1455/1500\n",
      "168/168 [==============================] - 0s 872us/step - loss: 0.0159 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1456/1500\n",
      "168/168 [==============================] - 0s 853us/step - loss: 0.0179 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1457/1500\n",
      "168/168 [==============================] - 0s 865us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1458/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0136 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1459/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0166 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1460/1500\n",
      "168/168 [==============================] - 0s 842us/step - loss: 0.0203 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1461/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0174 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1462/1500\n",
      "168/168 [==============================] - 0s 850us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1463/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0141 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1464/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1465/1500\n",
      "168/168 [==============================] - 0s 833us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1466/1500\n",
      "168/168 [==============================] - 0s 839us/step - loss: 0.0284 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1467/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1468/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0445 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1469/1500\n",
      "168/168 [==============================] - 0s 826us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1470/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1471/1500\n",
      "168/168 [==============================] - 0s 824us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1472/1500\n",
      "168/168 [==============================] - 0s 844us/step - loss: 0.0154 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1473/1500\n",
      "168/168 [==============================] - 0s 831us/step - loss: 0.0348 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1474/1500\n",
      "168/168 [==============================] - 0s 828us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1475/1500\n",
      "168/168 [==============================] - 0s 832us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1476/1500\n",
      "168/168 [==============================] - 0s 813us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1477/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0294 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1478/1500\n",
      "168/168 [==============================] - 0s 845us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1479/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1480/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1481/1500\n",
      "168/168 [==============================] - 0s 820us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1482/1500\n",
      "168/168 [==============================] - 0s 853us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1483/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1484/1500\n",
      "168/168 [==============================] - 0s 829us/step - loss: 0.0225 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1485/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0149 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1486/1500\n",
      "168/168 [==============================] - 0s 834us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1487/1500\n",
      "168/168 [==============================] - 0s 841us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1488/1500\n",
      "168/168 [==============================] - 0s 819us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1489/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1490/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0162 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1491/1500\n",
      "168/168 [==============================] - 0s 823us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1492/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0152 - acc: 0.9881 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1493/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0114 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1494/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1495/1500\n",
      "168/168 [==============================] - 0s 835us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1496/1500\n",
      "168/168 [==============================] - 0s 836us/step - loss: 0.0254 - acc: 0.9940 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1497/1500\n",
      "168/168 [==============================] - 0s 815us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1498/1500\n",
      "168/168 [==============================] - 0s 848us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 1499/1500\n",
      "168/168 [==============================] - 0s 838us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500/1500\n",
      "168/168 [==============================] - 0s 847us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1000\n",
    "EPOCHS = 1500\n",
    "#filepath=loc+\"modelc3-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "#callbacks_list = [checkpoint]\n",
    "x_train = np.load('completeset_x.npy')\n",
    "y_train = np.load('completeset_y.npy')\n",
    "history = model_c3.fit(x_train,\n",
    "                      y_train,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCHS,\n",
    "                      validation_split=0.3,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.02269735 -0.12190303]\n",
      "  [ 0.00634191 -0.16350758]\n",
      "  [ 0.02545108 -0.14587273]\n",
      "  ...\n",
      "  [ 0.02770412  0.14398939]\n",
      "  [ 0.01318449  0.15306364]\n",
      "  [ 0.00851151  0.10187121]]\n",
      "\n",
      " [[ 0.01368517  0.05992424]\n",
      "  [ 0.00751015  0.05923939]\n",
      "  [-0.01018043  0.0890303 ]\n",
      "  ...\n",
      "  [-0.00166892  0.0578697 ]\n",
      "  [ 0.00292062  0.06043788]\n",
      "  [ 0.01326794  0.05444545]]\n",
      "\n",
      " [[ 0.01326794  0.03355758]\n",
      "  [-0.00050068  0.07567576]\n",
      "  [-0.01560443  0.09159848]\n",
      "  ...\n",
      "  [-0.01819126  0.13491515]\n",
      "  [ 0.01243348  0.07687424]\n",
      "  [ 0.03638252  0.05889697]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.04674133  0.05480135]\n",
      "  [ 0.02537387  0.03219579]\n",
      "  [ 0.01235307  0.02534562]\n",
      "  ...\n",
      "  [-0.0480768  -0.27948687]\n",
      "  [ 0.         -0.34216591]\n",
      "  [ 0.05074773 -0.35518123]]\n",
      "\n",
      " [[ 0.10149547 -0.31168266]\n",
      "  [ 0.15758507 -0.26647155]\n",
      "  [ 0.21501013 -0.16474655]\n",
      "  ...\n",
      "  [ 0.01936427 -0.05445884]\n",
      "  [ 0.01135147  0.00616515]\n",
      "  [ 0.015024    0.00650766]]\n",
      "\n",
      " [[ 0.0310496  -0.02260556]\n",
      "  [ 0.03572373 -0.05103375]\n",
      "  [ 0.01135147 -0.03185328]\n",
      "  ...\n",
      "  [ 0.10249707  0.2726367 ]\n",
      "  [ 0.13388053  0.24146843]\n",
      "  [ 0.16893653  0.11850791]]]\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_train = np.load('completeset_x.npy')\n",
    "y_train = np.load('completeset_y.npy')\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
